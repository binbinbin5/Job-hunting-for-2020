# 海量数据处理总结
[toc]

# 1. 计算容量

在解决问题之前，要先计算一下海量数据需要占多大的容量。常见的单位换算如下：

- 1 byte = 8 bit
- 1 KB = 2<sup>10</sup> byte = 1024 byte ≈ 10<sup>3</sup> byte
- 1 MB = 2<sup>20</sup> byte ≈ 10 <sup>6</sup> byte
- 1 GB = 2<sup>30</sup> byte ≈ 10 <sup>9</sup> byte
- 1 亿 = 10<sup>8</sup>

1 个整数占 4 byte，1 亿个整数占 4*10<sup>8</sup> byte ≈ 400 MB。

# 2. 海量数据处理六种方法：
1. 分而治之/hash映射 + HashMap统计 + 堆/快速/归并排序
2. 多层划分
3. Bloom filter/Bitmap
4. Trie树/数据库/倒排索引
5. 外排序
6. 分布式处理之Hadoop/MapReduce

# 3. 海量数据拆分

可以将海量数据拆分到多台机器上和拆分到多个文件上：

- 如果数据量很大，无法放在一台机器上，就将数据拆分到多台机器上。这种方式可以让多台机器一起合作，从而使得问题的求解更加快速。但是也会导致系统更加复杂，而且需要考虑系统故障等问题；
- 如果在程序运行时无法直接加载一个大文件到内存中，就将大文件拆分成小文件，分别对每个小文件进行求解。

有以下策略进行拆分：

- 按出现的顺序拆分：当有新数据到达时，先放进当前机器，填满之后再将数据放到新增的机器上。这种方法的优点是充分利用系统的资源，因为每台机器都会尽可能被填满。缺点是需要一个查找表来保存数据到机器的映射，查找表可能会非常复杂并且非常大。



- 按散列值拆分：选取数据的主键 key，然后通过哈希取模 hash(key)%N 得到该数据应该拆分到的机器编号，其中 N 是机器的数量。优点是不需要使用查找表，缺点是可能会导致一台机器存储的数据过多，甚至超出它的最大容量。如果超过大小，那么在进行分类，合并的时候先合并他们。



- 按数据的实际含义拆分：例如一个社交网站系统，来自同一个地区的用户更有可能成为朋友，如果让同一个地区的用户尽可能存储在同一个机器上，那么在查找一个用户的好友信息时，就可以避免到多台机器上查找，从而降低延迟。缺点同样是需要使用查找表。





# 4. 判断一个数据是否已经存在

对于海量数据，要求判断一个数据是否已经存在。这个数据很有可能是字符串，例如 URL。

## 1. HashSet

最直观的方法是使用 HashSet 存储，那么就能以 O(1) 的时间复杂度判断一个数据是否已经存在。

考虑到数据是海量的，那么就需要使用拆分的方式将数据拆分到多台机器上，分别在每台机器上使用 HashSet 存储。我们需要使得相同的数据拆分到相同的机器上，可以使用哈希取模的拆分方式进行实现。

## 2. BitSet

如果海量数据是整数，并且范围不大时，就可以使用 BitSet 存储。通过构建一定大小的比特数组，并且让每个整数都映射到这个比特数组上，就可以很容易地知道某个整数是否已经存在。因为比特数组比整型数组小的多，所以通常情况下单机就能处理海量数据。

![](https://diycode.b0.upaiyun.com/photo/2019/5ed4c9af3cdb03261566394c3e52e0b4.png)

以下是一个 BitSet 的实现，当然在实际开发中可以直接使用语言内置的实现。

```java
class BitSet {
    int[] bitset;

    public BitSet(int size) {
        bitset = new int[(size >> 5) + 1]; // divide by 32
    }

    boolean get(int pos) {
        int wordNumber = (pos >> 5); // divide by 32
        int bitNumber = (pos & 0x1F); // mod 32
        return (bitset[wordNumber] & (1 << bitNumber)) != 0;
    }

    void set(int pos) {
        int wordNumber = (pos >> 5); // divide by 32
        int bitNumber = (pos & 0x1F); // mod 32
        bitset[wordNumber] |= 1 << bitNumber;
    }
}
```

使用 BitSet 还可以很容易地解决一个整数出现次数的问题，例如使用两个比特数组就可以存储 0~3 的信息。其实判重问题也可以简单看成一个数据出现的次数是否为 1，因此一个比特数组就够了。

## 3. 布隆过滤器

布隆过滤器能够以极小的空间开销解决海量数据判重问题，但是会有一定的误判概率。它主要用在网页黑名单系统、垃圾邮件过滤系统、爬虫的网址判重系统。

布隆过滤器也是使用 BitSet 存储数据，但是它进行了一定的改进，从而解除了 BitSet 要求数据的范围不大的限制。在存储时，它要求数据先经过 k 个哈希函得到 k 个位置，并将 BitSet 中对应位置设置为 1。在查找时，也需要先经过 k 个哈希函数得到 k 个位置，如果所有位置上都为 1，那么表示这个数据存在。

由于哈希函数的特点，两个不同的数通过哈希函数得到的值可能相同。如果两个数通过 k 个哈希函数得到的值都相同，那么使用布隆过滤器会将这两个数判为相同。

可以知道，令 k 和 m 都大一些会使得误判率降低，但是这会带来更高的时间和空间开销。

布隆过滤器会误判，也就是将一个不存在的数判断为已经存在，这会造成一定的问题。例如在垃圾邮件过滤系统中，会将一个邮件误判为垃圾邮件，那么就收不到这个邮件。可以使用白名单的方式进行补救。

![](https://diycode.b0.upaiyun.com/photo/2019/2d480a3fd9ab77dcd6297f55eafb7707.png)

## 4. Trie

Trie 树又叫又叫字典树、前缀树、单词查找树，它是一颗多叉查找树。与二叉查找树不同，键不是直接保存在节点中，而是由节点在树中的位置决定。

如果海量数据是字符串数据，那么就可以用很小的空间开销构建一颗 Trie 树，空间开销和树高有关。

![](https://diycode.b0.upaiyun.com/photo/2019/89c09aa7a8717a872c633824e0793514.png)

[Leetcode : Implement Trie (Prefix Tree)](https://leetcode.com/problems/implement-trie-prefix-tree/description/)

```java
class Trie {
    private class Node {
        Node[] childs = new Node[26];
        boolean isLeaf;
    }

    private Node root = new Node();

    public Trie() {
    }

    public void insert(String word) {
        insert(word, root);
    }

    private void insert(String word, Node node) {
        if (node == null) return;
        if (word.length() == 0) {
            node.isLeaf = true;
            return;
        }
        int index = indexForChar(word.charAt(0));
        if (node.childs[index] == null) {
            node.childs[index] = new Node();
        }
        insert(word.substring(1), node.childs[index]);
    }

    public boolean search(String word) {
        return search(word, root);
    }

    private boolean search(String word, Node node) {
        if (node == null) return false;
        if (word.length() == 0) return node.isLeaf;
        int index = indexForChar(word.charAt(0));
        return search(word.substring(1), node.childs[index]);
    }

    public boolean startsWith(String prefix) {
        return startWith(prefix, root);
    }

    private boolean startWith(String prefix, Node node) {
        if (node == null) return false;
        if (prefix.length() == 0) return true;
        int index = indexForChar(prefix.charAt(0));
        return startWith(prefix.substring(1), node.childs[index]);
    }

    private int indexForChar(char c) {
        return c - 'a';
    }
}
```
# 5. TopK
- 数据全排列，内存需求大，速度慢
- 局部淘汰：用最大最小堆
- 分治法：Hash分成N个，每个求最大的10个数，合并再求
- Hash法：直接Hash去重后排序




## 1. 问题描述

TopK Elements 问题用于找出一组数中最大的 K 个的数。



此外还有一种叫 Kth Element 问题，用于找出一组数中第 K 大的数。




其实要求解 TopK Elements，可以先求解 Kth Element，因为找到  Kth Element 之后，再遍历一遍，大于等于 Kth Element 的数都是 TopK Elements。

## 2. 一般解法

以 [Leetcode : 215. Kth Largest Element in an Array](https://leetcode.com/problems/kth-largest-element-in-an-array/description/) 为例，这是一道的 Kth Element 问题，不过这道题要找的是从后往前第 K 个元素，而不是从前往后。为了能和传统的 Kth Element 问题一样求解，可以先执行 `k = nums.length - k;`。

```
Input: [3,2,1,5,6,4] and k = 2
Output: 5
```

- 2.1 快速选择

快速排序的 partition() 方法，对于数组 nums 的 [l, h] 区间，会返回一个整数 k 使得 nums[l..k-1] 小于等于 nums[k]，且 nums[k+1..h] 大于等于 nums[k]，此时 nums[k] 就是数组的第 k 大元素。可以利用这个特性找出数组的 Kth Element，这种找 Kth Element 的算法称为快速选择算法。

- 时间复杂度 O(N)、空间复杂度 O(1)
- 只有当允许修改数组元素时才可以使用


```java
public int findKthElement(int[] nums, int k) {
    k = nums.length - k;
    int l = 0, h = nums.length - 1;
    while (l < h) {
        int j = partition(nums, l, h);
        if (j == k) {
            break;
        } else if (j < k) {
            l = j + 1;
        } else {
            h = j - 1;
        }
    }
    return nums[k];
}

private int partition(int[] a, int l, int h) {
    int i = l, j = h + 1;
    while (true) {
        while (a[++i] < a[l] && i < h) ;
        while (a[--j] > a[l] && j > l) ;
        if (i >= j) {
            break;
        }
        swap(a, i, j);
    }
    swap(a, l, j);
    return j;
}

private void swap(int[] a, int i, int j) {
    int t = a[i];
    a[i] = a[j];
    a[j] = t;
}
```

- 2.2 堆

维护一个大小为 K 的最小堆，堆顶元素就是 Kth Element。

使用大顶堆来维护最小堆，而不能直接创建一个小顶堆并设置一个大小，企图让小顶堆中的元素都是最小元素。

维护一个大小为 K 的最小堆过程如下：在添加一个元素之后，如果大顶堆的大小大于 K，那么需要将大顶堆的堆顶元素去除。

- 时间复杂度 O(NlogK) 、空间复杂度 O(K)
- 特别适合处理海量数据


```java
public int findKthLargest(int[] nums, int k) {
    k = nums.length - k + 1;
    PriorityQueue<Integer> pq = new PriorityQueue<>(Comparator.reverseOrder()); // 大顶堆
    for (int val : nums) {
        pq.add(val);
        if (pq.size() > k)  // 维护堆的大小为 K
            pq.poll();
    }
    return pq.peek();
}
```

## 3. 海量数据

在这种场景下，单机通常不能存放下所有数据。

- 拆分，可以按照哈希取模方式拆分到多台机器上，并在每个机器上维护最大堆；
- 整合，将每台机器得到的最大堆合并成最终的最大堆。

## 4. 频率统计

Heavy Hitters 问题要求找出一个数据流的最频繁出现的 K 个数，比如热门搜索词汇等。

- 4.1 HashMap

使用 HashMap 进行频率统计，然后使用快速选择或者堆的方式找出频率 TopK。在海量数据场景下，也是使用先拆分再整合的方式来解决空间问题。

- 4.2 Count-Min Sketch

维护 d*w 大小的二维统计数组，其中 d 是哈希函数的个数，w 根据情况而定。

- 在一个数到来时，计算 d 个哈希值，然后分别将哈希值对 w 取模，把对应统计数组上的值加 1；
- 要得到一个数的频率，也是要计算 d 个哈希值并取模，得到 d 个频率，取其中最小值。

该算法的思想和布隆过滤器类似，具有一定的误差，特别是当 w 很小时。但是它能够在单机环境下解决海量数据的频率统计问题。


```java
public class CountMinSketch {

    private int d;
    private int w;

    private long estimators[][];

    public CountMinSketch(int d, int w) {
        this.d = d;
        this.w = w;
    }

    public void add(int value) {
        for (int i = 0; i < d; i++)
            estimators[i][hash(value, i)]++;
    }

    public long estimateFrequency(int value) {
        long minimum = Integer.MAX_VALUE;
        for (int i = 0; i < d; i++) {
            minimum = Math.min(minimum, estimators[i][hash(value, i)]);
        }
        return minimum;
    }

    private int hash(int value, int i) {
        return 0; // use ith hash function
    }
}
```

- 4.3 Trie

Trie 树可以用于解决词频统计问题，只要在词汇对应节点保存出现的频率。它很好地适应海量数据场景，因为 Trie 树通常不高，需要的空间不会很大。

# 6. 海量数据的去重

==使用bitmap==，每一个数写入bitmap中，存在则1不存在则1 ，0位对应0,1对应1，那么我们遍历bitmap，把存在的位1的写入新文件就行了。

```
比如 电话号码 10000000-99999999 范围

bitmap[9999999-10000000] a= new biymap;

a[x-10000000] = 1;//存在
```



## 7. 海量数据的 排序

- ==数据库排序法==，导入数据库，进行索引操作提取文件，但是速度慢。
- ==分治法==：Hash分成N分，每份进行排序，速度慢 复杂
- ==位图法==

所谓的Bit-map就是用一个bit位来标记某个元素对应的Value， 而Key即是该元素。由于采用了Bit为单位来存储数据，因此在存储空间方面，可以大大节省。

1. 假设我们要对0-7内的5个元素(4,7,2,5,3)排序（这里假设这些元素没有重复）。那么我们就可以采用Bit-map的方法来达到排序的目的。要表示8个数，我们就只需要8个Bit（1Bytes），首先我们开辟1Byte的空间，将这些空间的所有Bit位都置为0
1. 然后遍历这5个元素，首先第一个元素是4，那么就把4对应的位置为1（可以这样操作 p+(i/8)|(0×01<<(i%8)) 当然了这里的操作涉及到Big-ending和Little-ending的情况，这里默认为Big-ending）,因为是从零开始的，所以要把第五位置为1。
1. 然后再处理第二个元素7，将第八位置为1,，接着再处理第三个元素，一直到最后处理完所有的元素，将相应的位置为1。
1. 然后我们现在遍历一遍Bit区域，将该位是一的位的编号输出（2，3，4，5，7），这样就达到了排序的目的。
1. 其实就是把计数排序用的统计数组的每个单位缩小成bit级别的布尔数组。



# 8. 例子

## 1、分而治之/hash映射 + HashMap统计 + 堆/快速/归并排序
适用范围：类似"出现次数最多前10"、"热门前10查询"、"频率最高前100"等跟频数排序有关问题

步骤：
1. 分而治之/hash映射：由于数据量过大，内存不足于存储所有数据，所以要需要将大文件（取模映射）化成小文件，逐个解决，最后汇总。
2. HashMap统计：当大文件转化了小文件后，那么便可以统计元素的出现次数，这里除了HasHMap，还可以使用trie树/搜索二叉树/红黑树
3. 堆排序：统计完了之后便进行排序，可先在小文件采取堆排序，得到每个小文件TopN，最后归并排序，得到大文件TopN。

问题实例：
1. 海量日志数据，提取出某日访问百度次数最多的那个IP（hash映射/一致性hash + HashMap统计 + 堆排序）
2. 寻找热门查询，300万个查询字符串中统计最热门的10个查询（数据规模小，可一次性存下，直接 HashMap/trie树/搜索二叉树/红黑树统计 + 堆排序）
3. 有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词（hash映射 + HashMap/trie树统计 + 堆排序/归并排序）
4. 海量数据分布在100台电脑中，想个办法高效统计出这批数据的TOP10（1、 HashMap统计 + 堆排序 2、 遍历全部 + hash映射 + HashMap统计 + 堆排序，控制同一个元素只会出现在一台电脑）
5. 有10个文件，每个文件1G，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复。要求你按照query的频度排序 （1、顺序读取10个文件，hash(query)%10的结果将query写入到另外10个文件 + HashMap统计 + 堆排序/归并排序 ， 2、hash映射 + 采用分布式的架构来处理，比如MapReduce + 合并）
6. 给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url （hash映射 + HashSet）
7. 怎么在海量数据中找出重复次数最多的一个?（同1）
8. 上千万或上亿数据（有重复），统计其中出现次数最多的前N个数据（同2）
9. 一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词，请给出思想，给出时间复杂度分析（同1，时间复杂度是O(n*lg10)）
10. 1000万字符串，其中有些是重复的，需要把重复的全部去掉，保留没有重复的字符串。请怎么设计和实现？（1、trie树/HashMap  2、LinkedHashSet）
11. 一个文本文件，找出前10个经常出现的词，但这次文件比较长，说是上亿行或十亿行，总之无法一次读入内存，问最优解（同1）
12.  100w个数中找出最大的100个数（1、局部淘汰法，O(100w*100)  2、快速排序，O(100w*100)  3、用一个含100个元素的最小堆完成，O(100w*lg100)）




## 2、多层划分
适用范围：第k大，中位数，不重复或重复的数字

基本原理及要点：因为元素范围很大，不能利用直接寻址表，所以通过多次划分，逐步确定范围，然后最后在一个可以接受的范围内进行。

>问题实例：
- 判断一个数是否存在30亿个整数中？

    采用 bitmap 算法的话，一一映射，如果存在为1，不存在为0，直接取下标。

- 如果有2GB 的内存，并给20 亿个 int 型整数，找出次数出现最多的数？

    把20亿个整数用哈希函数映射，根据哈希函数得到的哈希值，再把他们存放到对应的文件中。每个文件采用哈希表来统计，把这个数作为 key，把这个数出现的次数作为 value，取每个文件最多的数来进行比较，就是结果。如果变成40亿个数字超过整形，那么当超过int整形的时候，他必定为最多出现的次。

- 2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数

    整数个数为2^32,也就是，我们可以将这2^32个数，划分为2^8个区域(比如用单个文件代表一个区域)，然后将数据分离到不同的区域，然后不同的区域在利用bitmap（通过一个bit位来表示某个元素对应的值）就可以直接解决了

- 5亿个int找它们的中位数

    **思路一**：首先我们将int划分为2^16个区域，然后读取数据统计落到各个区域里的数的个数，之后我们根据统计结果就可以判断中位数落到那个区域，同时知道这个区域中的第几大数刚好是中位数。然后第二次扫描我们只统计落在这个区域中的那些数就可以了。

    实际上，如果不是int是int64，我们可以经过3次这样的划分即可降低到可以接受的程度。即可以先将int64分成2^24个区域，然后确定区域的第几大数，在将该区域分成2^20个子区域，然后确定是子区域的第几大数，然后子区域里的数的个数只有2^20，就可以直接利用direct addr table进行统计了。
　　

    **思路二**：同样需要做两遍统计，如果数据存在硬盘上，就需要读取2次。

    同基数排序类似，开一个大小为65536的Int数组，第一遍读取，统计Int32的高16位的情况，也就是0-65535，都算作0,65536 - 131071都算作1。就相当于用该数除以65536。Int32 除以 65536的结果不会超过65536种情况，因此开一个长度为65536的数组计数就可以。每读取一个数，数组中对应的计数+1，考虑有负数的情况，需要将结果加32768后，记录在相应的数组内。
    第一遍统计之后，遍历数组，逐个累加统计，看中位数处于哪个区间，比如处于区间k，那么0- k-1的区间里数字的数量sum应该<n/2（2.5亿）。而k+1 - 65535的计数和也<n/2，第二遍统计同上面的方法类似，但这次只统计处于区间k的情况，也就是说(x / 65536) + 32768 = k。统计只统计低16位的情况。并且利用刚才统计的sum，比如sum = 2.49亿，那么现在就是要在低16位里面找100万个数(2.5亿-2.49亿)。这次计数之后，再统计一下，看中位数所处的区间，最后将高位和低位组合一下就是结果了。

## 3、Bloom filter/Bitmap
适用范围：==可以用来实现数据字典，进行数据的判重，或者集合求交集==

基本原理及要点：
1. Bloom filter：利用位数组很简洁地表示一个集合，并能判断一个元素是否属于这个集合，在判断一个元素是否属于某个集合时，有可能会把不属于这个集合的元素误认为属于这个集合（false positive）。因此，Bloom 
Filter不适合那些“零错误”的应用场合。而在能容忍低错误率的应用场合下，Bloom Filter通过极少的错误换取了存储空间的极大节省。
2. Bitmap：通过一个bit数组来存储特定数据的一种数据结构；由于bit是数据的最小单位，所以这种数据结构往往是非常节省存储空间



问题实例：

-  给你A,B两个文件，各存放50亿条URL，每条URL占用64字节，内存限制是4G，让你找出A,B文件共同的URL。如果是三个乃至n个文件呢？

    根据这个问题我们来计算下内存的占用，4G=2^32大概是40亿*8大概是340亿，n=50亿，如果按出错率0.01算需要的大概是650亿个bit。现在可用的是340亿，相差并不多，这样可能会使出错率上升些。另外如果这些urlip是一一对应的，就可以转换成ip，则大大简单了。

    同时，上文的第5题：给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？如果允许有一定的错误率，可以使用Bloom filter，4G内存大概可以表示340亿bit。将其中一个文件中的url使用Bloom filter映射为这340亿bit，然后挨个读取另外一个文件的url，检查是否与Bloom filter，如果是，那么该url应该是共同的url（注意会有一定的错误率）。

- 在2.5亿个整数中找出不重复的整数，注，内存不足以容纳这2.5亿个整数。

    思路一：采用2-Bitmap（每个数分配2bit，00表示不存在，01表示出现一次，10表示多次，11无意义）进行，共需内存2^32 * 2 bit=1 GB内存，还可以接受。然后扫描这2.5亿个整数，查看Bitmap中相对应位，如果是00变01，01变10，10保持不变。所描完事后，查看bitmap，把对应位是01的整数输出即可。

    思路二：也可采用与第1题类似的方法，进行划分小文件的方法。然后在小文件中找出不重复的整数，并排序。然后再进行归并，注意去除重复的元素。

- 给40亿个不重复的unsigned     int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中？

    用位图/Bitmap的方法，申请512M的内存，一个bit位代表一个unsigned int值。读入40亿个数，设置相应的bit位，读入要查询的数，查看相应bit位是否为1，为1表示存在，为0表示不存在。

## 4、Trie树/数据库/倒排索引

### Trie树
适用范围：数据量大，重复多，但是数据种类小可以放入内存

基本原理及要点：是一种哈希树的变种，排序和保存大量的字符串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计。它的优点是：利用字符串的公共前缀来减少查询时间，最大限度地减少无谓的字符串比较，查询效率比哈希树高。

问题实例：
1. 寻找热门查询：查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个，每个不超过255字节。
2. 有10个文件，每个文件1G，每个文件的每一行都存放的是用户的query，每个文件的query都可能重复。要你按照query的频度排序。
3. 1000万字符串，其中有些是相同的(重复),需要把重复的全部去掉，保留没有重复的字符串。请问怎么设计和实现？
4. 一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词。其解决方法是：用trie树统计每个词出现的次数，时间复杂度是O(n*le)（le表示单词的平准长度），然后是找出出现最频繁的前10个词。


### 数据库索引
适用范围：大数据量的增删改查

基本原理及要点：利用数据库索引（B 树、B+ 树、B* 树及R 树）的设计实现方法，对海量数据的增删改查进行处理。

### 倒排索引
适用范围：搜索引擎，关键字查询

基本原理及要点：从关键字到文档的映射过程，保存这种映射这种信息的索引

问题实例：
1. 文档检索系统，查询那些文件包含了某单词，比如常见的学术论文的关键字搜索


## 5、外排序
适用范围：大数据的排序，去重

基本原理及要点：外部排序指的是大文件的排序，即待排序的记录存储在外存储器上，待排序的文件无法一次装入内存，需要在内存和外部存储器之间进行多次数据交换，以达到排序整个文件的目的。

处理过程 ：
1. 按可用内存的大小，把外存上含有n个记录的文件分成若干个长度为L的子文件，把这些子文件依次读入内存，并利用有效的内部排序方法对它们进行排序，再将排序后得到的有序子文件重新写入外存。
2. 对这些有序子文件逐趟归并，使其逐渐由小到大，直至得到整个有序文件为止。

问题实例：
1. 如何给10^7个数据量的磁盘文件排序

## 6、 分布式处理之Hadoop/MapReduce
适用范围：数据量大，但是数据种类小可以放入内存

基本原理及要点：将数据交给不同的机器去处理，数据划分，结果归约。

问题实例：
1. 海量数据分布在100台电脑中，想个办法高效统计出这批数据的TOP10。
2. 一共有N个机器，每个机器上有N个数。每个机器最多存O(N)个数并对它们操作。如何找到N^2个数的中数(median)？

---
资料来源：[教你如何迅速秒杀掉：99%的海量数据处理面试题](https://blog.csdn.net/v_JULY_v/article/details/7382693)

