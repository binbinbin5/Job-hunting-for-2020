[toc]

## JVM 发生内存溢出的 8 种原因、及解决办法

1. Java 堆空间
2. GC 开销超过限制
3. 请求的数组大小超过虚拟机限制
4. Perm gen 空间
5. Metaspace
6. 无法新建本机线程
7. 杀死进程或子进程
8. 发生 stack_trace_with_native_method

**1. Java 堆空间**

**发生频率**：5颗星

**造成原因**

- 无法在 Java 堆中分配对象
- 吞吐量增加
- 应用程序无意中保存了对象引用，对象无法被 GC 回收
- 应用程序过度使用 finalizer。finalizer 对象不能被 GC 立刻回收。finalizer 由结束队列服务的守护线程调用，有时 finalizer 线程的处理能力无法跟上结束队列的增长

**解决方案**

- 使用 -Xmx 增加堆大小
- 修复应用程序中的内存泄漏

**2. GC 开销超过限制**

**发生频率**：5颗星

**造成原因**

- Java 进程98%的时间在进行垃圾回收，恢复了不到2%的堆空间，最后连续5个（编译时常量）垃圾回收一直如此。

**解决方案**

- 使用 -Xmx 增加堆大小
- 使用 -XX:-UseGCOverheadLimit 取消 GC 开销限制
- 修复应用程序中的内存泄漏

**3. 请求的数组大小超过虚拟机限制**

**发生频率**：2颗星

**造成原因**

- 应用程序试图分配一个超过堆大小的数组

**解决方案**

- 使用 -Xmx 增加堆大小
- 修复应用程序中分配巨大数组的 bug

**4. Perm gen 空间**

**发生频率**：3颗星

**造成原因**

Perm gen 空间包含：

- 类的名字、字段、方法
- 与类相关的对象数组和类型数组
- JIT 编译器优化

当 Perm gen 空间用尽时，将抛出异常。

**解决方案**

- 使用 -XX: MaxPermSize 增加 Permgen 大小
- 不重启应用部署应用程序可能会导致此问题。重启 JVM 解决

**5. Metaspace**

**发生频率**：3颗星

**造成原因**

- 从 Java 8 开始 Perm gen 改成了 Metaspace，在本机内存中分配 class 元数据（称为 metaspace）。如果 metaspace 耗尽，则抛出异常

**解决方案**

- 通过命令行设置 -XX: MaxMetaSpaceSize 增加 metaspace 大小
- 取消 -XX: maxmetsspacedize
- 减小 Java 堆大小,为 MetaSpace 提供更多的可用空间
- 为服务器分配更多的内存
- 可能是应用程序 bug，修复 bug

**6. 无法新建本机线程**

**发生频率**：5颗星

**造成原因**

- 内存不足，无法创建新线程。由于线程在本机内存中创建，报告这个错误表明本机内存空间不足

**解决方案**

- 为机器分配更多的内存
- 减少 Java 堆空间
- 修复应用程序中的线程泄漏。
- 增加操作系统级别的限制

- - ulimit -a
  - 用户进程数增大 (-u) 1800

- 使用 -Xss 减小线程堆栈大小

**7. 杀死进程或子进程**

**发生频率**：1颗星

**造成原因**

- 内核任务：内存不足结束器，在可用内存极低的情况下会杀死进程

**解决方案**

- 将进程迁移到不同的机器上
- 给机器增加更多内存
- 与其他 OOM 错误不同，这是由操作系统而非 JVM 触发的。

**8. 发生 stack_trace_with_native_method**

**发生频率**：1颗星

**造成原因**

- 本机方法（native method）分配失败
- 打印的堆栈跟踪信息，最顶层的帧是本机方法

**解决方案**

- 使用操作系统本地工具进行诊断

## 17 个 JVM 参数

大家都知道，jvm在启动的时候，会执行默认的一些参数。一般情况下，这些设置的默认参数应对一些平常的项目也够用了。但是如果项目特别大了，需要增加一下堆内存的大小、或者是系统老是莫明的挂掉，想查看下gc日志来排查一下错误的原因，都需要咱们手动设置这些参数。



**1.verbose:gc**

表示，启动jvm的时候，输出jvm里面的gc信息。格式如下：

```
[Full GC 178K->99K(1984K)， 0.0253877 secs]
```

解读：Full GC 就表示执行了一次Full GC的操作，178K 和99K 就表示执行GC前内存容量和执行GC后的内存容量。1984K就表示内存总容量。后面那个是执行本次GC所消耗的时间，单位是秒。



**2.-XX:+printGC**

GC信息跟上个一样，就不做介绍了。



**3.-XX:+PrintGCDetails**

GC的详细信息。格式如下：

```
–Heap
– def new generation   total 13824K, used 11223K [0x27e80000, 0x28d80000, 0x28d80000)
–  eden space 12288K,  91% used [0x27e80000, 0x28975f20, 0x28a80000)
–  from space 1536K,   0% used [0x28a80000, 0x28a80000, 0x28c00000)
–  to   space 1536K,   0% used [0x28c00000, 0x28c00000, 0x28d80000)
– tenured generation   total 5120K, used 0K [0x28d80000, 0x29280000, 0x34680000)
–   the space 5120K,   0% used [0x28d80000, 0x28d80000, 0x28d80200, 0x29280000)
– compacting perm gen  total 12288K, used 142K [0x34680000, 0x35280000, 0x38680000)
–   the space 12288K,   1% used [0x34680000, 0x346a3a90, 0x346a3c00, 0x35280000)
–    ro space 10240K,  44% used [0x38680000, 0x38af73f0, 0x38af7400, 0x39080000)
–    rw space 12288K,  52% used [0x39080000, 0x396cdd28, 0x396cde00, 0x39c80000)
```

解读：

- new generation 就是堆内存里面的新生代。total的意思就是一共的，所以后面跟的就是新生代一共的内存大小。used也就是使用了多少内存大小。0x开头的那三个分别代表的是 底边界，当前边界，高边界。也就是新生代这片内存的起始点，当前使用到的地方和最大的内存地点。

- eden space 这个通常被翻译成伊甸园区，是在新生代里面的，一些创建的对象都会先被放进这里。后面那个12288K就表示伊甸园区一共的内存大小，91% used，很明显，表示已经使用了百分之多少。后面的那个0x跟上一行的解释一样。

- from space 和to space 是幸存者的两个区。也是属于新生代的。他两个区的大小必须是一样的。因为新生代的GC采用的是复制算法，每次只会用到一个幸存区，当一个幸存区满了的时候，把还是活的对象复制到另个幸存区，上个直接清空。这样做就不会产生内存碎片了。

- tenured generation 就表示老年代。

- compacting perm 表示永久代。由于这两个的格式跟前面我介绍的那个几乎一样，我就不必介绍了。



**4.-XX:+PrintGCTimeStamps**

打印GC发生的时间戳。格式如下：

```
289.556: [GC [PSYoungGen: 314113K->15937K(300928K)] 405513K->107901K(407680K), 0.0178568 secs] [Times: user=0.06 sys=0.00, real=0.01 secs] 

293.271: [GC [PSYoungGen: 300865K->6577K(310720K)] 392829K->108873K(417472K), 0.0176464 secs] [Times: user=0.06 sys=0.00, real=0.01 secs]
```

解读：289.556表示从jvm启动到发生垃圾回收所经历的的时间。GC表示这是新生代GC（Minor GC）。PSYoungGen表示新生代使用的是多线程垃圾回收器Parallel Scavenge。314113K->15937K(300928K)]这个跟上面那个GC格式一样。

只不过，这个是表示的是新生代，幸存者区。后面那个是整个堆的大小，GC前和GC后的情况。Times这个显而易见，代表GC的所消耗的时间，用户垃圾回收的时间和系统消耗的时间和最终真实的消耗时间。



**5.-X:loggc:log/gc.log**

这个就表示，指定输出gc.log的文件位置。（我这里写的log/gc.log就表示在当前log的目录里，把GC日志写到叫gc.log的文件里。）



**6.-XX:+PrintHeapAtGC**

表示每次GC后，都打印堆的信息。（这个打印的基本格式跟上面第二条的基本类似，我也就不比多说了。）



**7.-XX:+TraceClassLoading**

监控类的加载。格式如下：

```
•[Loaded java.lang.Object from shared objects file]

•[Loaded java.io.Serializable from shared objects file]

•[Loaded java.lang.Comparable from shared objects file]

•[Loaded java.lang.CharSequence from shared objects file]

•[Loaded java.lang.String from shared objects file]

•[Loaded java.lang.reflect.GenericDeclaration from shared objects file]

•[Loaded java.lang.reflect.Type from shared objects file]
```

使用这个参数就能很清楚的看到那些类被加载的情况了。



**8.-XX:+PrintClassHistogram**

跟踪参数。这个按下Ctrl+Break后，就会打印一下信息：

```
num     #instances         #bytes  class name
\---------------------------------------------
   1:        890617      470266000  [B
   2:        890643       21375432  java.util.HashMap$Node
   3:        890608       14249728  java.lang.Long
   4:            13        8389712  [Ljava.util.HashMap$Node;
   5:          2062         371680  [C
   6:           463          41904  java.lang.Class
```

分别显示：序号、实例数量、总大小、类型。

这里面那个类型，B和C的其实就是byte和char类型。



**9.-Xmx -Xms**

这个就表示设置堆内存的最大值和最小值。这个设置了最大值和最小值后，jvm启动后，并不会直接让堆内存就扩大到指定的最大数值。而是会先开辟指定的最小堆内存，如果经过数次GC后，还不能，满足程序的运行，才会逐渐的扩容堆的大小，但也不是直接扩大到最大内存。



**10.-Xmn**

设置新生代的内存大小。



**11.-XX:NewRatio**

新生代和老年代的比例。比如：1：4，就是新生代占五分之一。



**12.-XX:SurvivorRatio**

设置两个Survivor区和eden区的比例。比如：2：8 ，就是一个Survivor区占十分之一。



**13.-XX:+HeapDumpOnOutMemoryError**

发生OOM时，导出堆的信息到文件。



**14.-XX:+HeapDumpPath**

表示，导出堆信息的文件路径。



**15.-XX:OnOutOfMemoryError**

当系统产生OOM时，执行一个指定的脚本，这个脚本可以是任意功能的。比如生成当前线程的dump文件，或者是发送邮件和重启系统。



**16.-XX:PermSize -XX:MaxPermSize**

设置永久区的内存大小和最大值。永久区内存用光也会导致OOM的发生。



**17.-Xss**

设置栈的大小。栈都是每个线程独有一个，所有一般都是几百k的大小。

## 调试和优化

### 调优

从性能的角度看，通常关注三个方面，内存占用（footprint）、延时（latency）和吞吐量（throughput），大多数情况下调优会侧重于其中一个或者两个方面的目标，很少有情况可以兼顾三个不同的角度。当然，除了上面通常的三个方面，也可能需要考虑其他 GC 相关的场景，例如，OOM 也可能与不合理的 GC 相关参数有关；或者，应用启动速度方面的需求，GC 也会是个考虑的方面。

基本的调优思路可以总结为：

1. 理解应用需求和问题，确定调优目标。假设，我们开发了一个应用服务，但发现偶尔会出现性能抖动，出现较长的服务停顿。评估用户可接受的响应时间和业务量，将目标简化为，希望 GC 暂停尽量控制在 200ms 以内，并且保证一定标准的吞吐量。
2. 掌握 JVM 和 GC 的状态，定位具体的问题，确定真的有 GC 调优的必要。具体有很多方法，比如，通过 jstat 等工具查看 GC 等相关状态，可以开启 GC 日志，或者是利用操作系统提供的诊断工具等。例如，通过追踪 GC 日志，就可以查找是不是 GC 在特定时间发生了长时间的暂停，进而导致了应用响应不及时。
3. 这里需要思考，选择的 GC 类型是否符合我们的应用特征，如果是，具体问题表现在哪里，是 Minor GC 过长，还是 Mixed GC 等出现异常停顿情况；如果不是，考虑切换到什么类型，如 CMS 和 G1 都是更侧重于低延迟的 GC 选项。
4. 通过分析确定具体调整的参数或者软硬件配置。
5. 验证是否达到调优目标，如果达到目标，即可以考虑结束调优；否则，重复完成分析、调整、验证这个过程。

### 优化

JVM 在对代码执行的优化可分为运行时（runtime）优化和即时编译器（JIT）优化。运行时优化主要是解释执行和动态编译通用的一些机制，比如说锁机制（如偏斜锁）、内存分配机制（如 TLAB）等。除此之外，还有一些专门用于优化解释执行效率的，比如说模版解释器、内联缓存（inline cache，用于优化虚方法调用的动态绑定）。

JVM 的即时编译器优化是指将热点代码以方法为单位转换成机器码，直接运行在底层硬件之上。它采用了多种优化方式，包括静态编译器可以使用的如方法内联、逃逸分析，也包括基于程序运行 profile 的投机性优化（speculative/optimistic optimization）。这个怎么理解呢？比如我有一条 instanceof 指令，在编译之前的执行过程中，测试对象的类一直是同一个，那么即时编译器可以假设编译之后的执行过程中还会是这一个类，并且根据这个类直接返回 instanceof 的结果。如果出现了其他类，那么就抛弃这段编译后的机器码，并且切换回解释执行。

当然，JVM 的优化方式仅仅作用在运行应用代码的时候。如果应用代码本身阻塞了，比如说并发时等待另一线程的结果，这就不在 JVM **的优化范畴啦**

## GC暂停和JVM内存分配

### 1、是否依赖Java系统自身内存处理数据？

不管是我们自己开发的Java应用系统，还是一些中间件系统，在实现的时候都需要选择是否基于自己Java进程的内存来处理数据。

Java、Scala等编程语言底层依赖的都是JVM，那么只要是使用JVM，就可以考虑在JVM进程的内存中来放置大量的数据。

> 比如说系统A可以给系统B发送一条消息，那么中间需要依赖一个消息中间件，系统A要先把消息发送到消息中间件，然后系统B从这个消息中间件消费到这条消息。![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs/20190527131754.png)一条消息发送到消息中间件之后，有一种处理方式，就是把这条数据先缓冲在自己的JVM内存里。然后过一段时间之后，再从自己的内存刷新到磁盘上去，这样可以持久化保存这条消息，如下图。![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs/20190527131830.png)

### 2、依赖Java系统自身内存有什么缺陷

依赖Java系统自身内存处理数据，比如说设计一个内存缓冲区，来缓冲住高并发写入的大量消息，那么是有其缺陷的。最大的缺陷，其实就是JVM的GC问题。

如果一个Java进程里老是塞入很多的数据，这些数据都是用来缓冲在内存里的，但是过一会儿这些数据都会写入磁盘。写入之后，此时就会依托JVM垃圾回收机制，把内存里那些不需要的数据给回收掉，释放掉那些内存空间腾出来。但是JVM垃圾回收的时候，有一种情况叫做stop the world，就是他会停止你的工作线程，就专门让他进行垃圾回收。他在垃圾回收的时候，有可能你的这个中间件系统就运行不了了。

> 比如你发送请求给他，他可能都没法响应给你，因为他的接收请求的工作线程都停了，现在人家后台的垃圾回收线程正在回收垃圾对象。![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs/20190527132016.png)

虽然说现在JVM的垃圾回收器一直在不断的演进和发展，从CMS到G1，尽可能的在降低垃圾回收的时候的影响，减少工作线程的停顿。但是你要是完全依赖JVM内存来管理大量的数据，那在垃圾回收的时候，或多或少总是有影响的。

### 3、优化为依赖OS Cache而不是JVM

类似Kafka、Elasticsearch等分布式中间件系统，虽然也是基于JVM运行的，但是他们都选择了依赖OS Cache来管理大量的数据.也就是说，是操作系统管理的内存缓冲，而不是依赖JVM自身内存来管理大量的数据.

> 比如说Kafka吧，如果你写一条数据到Kafka，他实际上会直接写入磁盘文件。但是磁盘文件在写入之前其实会进入os cache，也就是操作系统管理的内存空间，然后过一段时间，操作系统自己会选择把他的os cache的数据刷入磁盘。然后后续在消费数据的时候，其实也会优先从os cache（内存缓冲）里来读取数据。相当于写数据和读数据都是依托于os cache来进行的，完全依托操作系统级别的内存区域来进行，读写性能都很高。

此外，还有另外一个好处，就是不要依托自身JVM来缓冲大量的数据，这样可以避免复杂而且耗时的JVM垃圾回收操作。

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs/20190527132158.png)

大量的依赖os cache来缓冲大量的数据，然后在进行搜索和查询的时候，也可以优先从os cache（内存区域）中读取数据，这样就可以保证非常高的读写性能。

### 4、依赖os cache的系统JVM内存越大越好？

明显不是的，假如说你有一台机器，有32GB的内存，现在你如果在搞不清楚状况的情况下，要是傻傻的认为还是给JVM分配越大内存越好，此时比如给了16G的堆内存空间给JVM，那么os cache剩下的内存，可能就不到10GB了，因为本身其他的程序还要占用几个GB的内存。

那如果是这样的话，就会导致你在写入磁盘的时候，os cache能容纳的数据量很有限。

> 比如说一共有20G的数据要写入磁盘，现在就只有10GB的数据可以放在os cache里，然后另外10GB的数据就只能放在磁盘上。此时在读取数据的时候，那么起码有一半的读取请求，必须从磁盘上去读了，没法从os cache里读，谁让你os cache里就只能放的下10G的一半大小的数据啊，另外一半都在磁盘里，这也是没办法的，如下图。![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs/20190527132302.png)那此时你有一半的请求都是从磁盘上在读取数据，必然会导致性能很差。

所以很多人在用Elasticsearch的时候就是这样的一个问题，老是觉得ES读取速度慢，几个亿的数据写入ES，读取的时候要好几秒。那能不花费好几秒吗？你要是ES集群部署的时候，给JVM内存过大，给os cache留了几个GB的内存，导致几亿条数据大部分都在磁盘上，不在os cache里，最后读取的时候大量读磁盘，耗费个几秒钟是很正常的。

### 5、正确的做法

针对场景合理给os cache更大内存,所以说，针对类似Kafka、Elasticsearch这种生产系统部署的时候，应该要给JVM比如6GB或者几个GB的内存就可以了.

因为他们可能不需要耗费过大的内存空间，不依赖JVM内存管理数据，当然具体是设置多少，需要你精准的压测和优化。

但是对于这类系统，应该给os cache留出来足够的内存空间，比如32GB内存的机器，完全可以给os cache留出来20多G的内存空间，那么此时假设你这台机器总共就写入了20GB的数据，就可以全部驻留在os cache里了。

然后后续在查询数据的时候，不就可以全部从os cache里读取数据了，完全依托内存来走，那你的性能必然是毫秒级的，不可能出现几秒钟才完成一个查询的情况。

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs/20190527132410.png)

## 内存泄漏排查

人人都会犯错，但一些错误是如此的荒谬，我想不通怎么会有人犯这种错误。更没想到的是，这种事竟发生在了我们身上。当然，这种东西只有事后才能发现真相。接下来，我将讲述一系列最近在我们一个应用上犯过的这种错误。最有意思的是，一开始的迹象揭示的问题，与实际发生的问题完全不同。

**在一个凄凉的午夜**

午夜刚过，我就被一条来自监控系统的警报吵醒了。Adventory，我们的 PPC （以点击次数收费）广告系统中一个负责索引广告的应用，很明显连续重启了好几次。在云端的环境里，实例的重启是很正常的，也不会触发报警，但这次实例重启的次数在短时间内超过了阈值。我打开了笔记本电脑，一头扎进项目的日志里。

**一定是网络的问题**

我看到服务在连接 ZooKeeper 时发生了数次超时。我们使用 ZooKeeper（ZK）协调多个实例间的索引操作，并依赖它实现鲁棒性。很显然，一次 Zookeeper 失败会阻止索引操作的继续运行，不过它应该不会导致整个系统挂掉。而且，这种情况非常罕见（这是我第一次遇到 ZK 在生产环境挂掉），我觉得这个问题可能不太容易搞定。于是我把 ZooKeeper 的值班人员喊醒了，让他们看看发生了什么。

同时，我检查了我们的配置，发现 ZooKeeper 连接的超时时间是秒级的。很明显，ZooKeeper 全挂了，由于其他服务也在使用它，这意味着问题非常严重。我给其他几个团队发了消息，他们显然还不知道这事儿。

ZooKeeper 团队的同事回复我了，在他看来，系统运行一切正常。由于其他用户看起来没有受到影响，我慢慢意识到不是 ZooKeeper 的问题。日志里明显是网络超时，于是我把负责网络的同事叫醒了。

负责网络的团队检查了他们的监控，没有发现任何异常。由于单个网段，甚至单个节点，都有可能和剩余的其他节点断开连接，他们检查了我们系统实例所在的几台机器，没有发现异常。其间，我尝试了其他几种思路，不过都行不通，我也到了自己智力的极限。时间已经很晚了（或者说很早了），同时，跟我的尝试没有任何关系，重启变得不那么频繁了。由于这个服务仅仅负责数据的刷新，并不会影响到数据的可用性，我们决定把问题放到上午再说。

**一定是 GC 的问题**

有时候把难题放一放，睡一觉，等脑子清醒了再去解决是一个好主意。没人知道当时发生了什么，服务表现的非常怪异。突然间，我想到了什么。Java 服务表现怪异的主要根源是什么？当然是垃圾回收。

为了应对目前这种情况的发生，我们一直打印着 GC 的日志。我马上把 GC 日志下载了下来，然后打开 Censum开始分析日志。我还没仔细看，就发现了一个恐怖的情况：每15分钟发生一次 full GC，每次 GC 引发长达 20 秒的服务停顿。怪不得连接 ZooKeeper 超时了，即使 ZooKeeper 和网络都没有问题。

这些停顿也解释了为什么整个服务一直是死掉的，而不是超时之后只打一条错误日志。我们的服务运行在 Marathon 上，它定时检查每个实例的健康状态，如果某个端点在一段时间内没有响应，Marathon 就重启那个服务。



知道原因之后，问题就解决一半了，因此我相信这个问题很快就能解决。为了解释后面的推理，我需要说明一下 Adventory 是如何工作的，它不像你们那种标准的微服务。

Adventory 是用来把我们的广告索引到 ElasticSearch (ES) 的。这需要两个步骤。第一步是获取所需的数据。到目前为止，这个服务从其他几个系统中接收通过 Hermes 发来的事件。数据保存到 MongoDB 集群中。数据量最多每秒几百个请求，每个操作都特别轻量，因此即便触发一些内存的回收，也耗费不了多少资源。第二步就是数据的索引。这个操作定时执行（大概两分钟执行一次），把所有 MongoDB 集群存储的数据通过 RxJava 收集到一个流中，组合为非范式的记录，发送给 ElasticSearch。这部分操作类似离线的批处理任务，而不是一个服务。

由于经常需要对数据做大量的更新，维护索引就不太值得，所以每执行一次定时任务，整个索引都会重建一次。这意味着一整块数据都要经过这个系统，从而引发大量的内存回收。尽管使用了流的方式，我们也被迫把堆加到了 12 GB 这么大。由于堆是如此巨大（而且目前被全力支持），我们的 GC 选择了 G1。

我以前处理过的服务中，也会回收大量生命周期很短的对象。有了那些经验，我同时增加了 -XX:G1NewSizePercent 和 -XX:G1MaxNewSizePercent 的默认值，这样新生代会变得更大，young GC 就可以处理更多的数据，而不用把它们送到老年代。Censum 也显示有很多过早提升。这和一段时间之后发生的 full GC 也是一致的。不幸的是，这些设置没有起到任何作用。

接下来我想，或许生产者制造数据太快了，消费者来不及消费，导致这些记录在它们被处理前就被回收了。我尝试减小生产数据的线程数量，降低数据产生的速度，同时保持消费者发送给 ES 的数据池大小不变。这主要是使用背压（backpressure）机制，不过它也没有起到作用。

**一定是内存泄漏**

这时，一个当时头脑还保持冷静的同事，建议我们应该做一开始就做的事情：检查堆中的数据。我们准备了一个开发环境的实例，拥有和线上实例相同的数据量，堆的大小也大致相同。把它连接到 jnisualvm ，分析内存的样本，我们可以看到堆中对象的大致数量和大小。大眼一看，可以发现我们域中Ad对象的数量高的不正常，并且在索引的过程中一直在增长，一直增长到我们处理的广告的数量级别。但是……这不应该啊。毕竟，我们通过 RX 把这些数据整理成流，就是为了防止把所有的数据都加载到内存里。



随着怀疑越来越强，我检查了这部分代码。它们是两年前写的，之后就没有再被仔细的检查过。果不其然，我们实际上把所有的数据都加载到了内存里。这当然不是故意的。由于当时对 RxJava 的理解不够全面，我们想让代码以一种特殊的方式并行运行。为了从 RX 的主工作流中剥离出来一些工作，我们决定用一个单独的 executor 跑 CompetableFuture。但是，我们因此就需要等待所有的 CompetableFuture 都工作完……通过存储他们的引用，然后调用 join()。这导致一直到索引完成，所有的 future 的引用，以及它们引用到的数据，都保持着生存的状态。这阻止了垃圾收集器及时的把它们清理掉。

**真有这么糟糕吗？**

当然这是一个很愚蠢的错误，对于发现得这么晚，我们也很恶心。我甚至想起很久之前，关于这个应用需要 12 GB 的堆的问题，曾有个简短的讨论。12 GB 的堆，确实有点大了。但是另一方面，这些代码已经运行了将近两年了，没有发生过任何问题。我们可以在当时相对容易的修复它，然而如果是两年前，这可能需要我们花费更多的时间，而且相对于节省几个 G 的内存，当时我们有很多更重要的工作。

因此，虽然从纯技术的角度来说，这个问题如此长时间没解决确实很丢人，然而从战略性的角度来看，或许留着这个浪费内存的问题不管，是更务实的选择。当然，另一个考虑就是这个问题一旦发生，会造成什么影响。我们几乎没有对用户造成任何影响，不过结果有可能更糟糕。软件工程就是权衡利弊，决定不同任务的优先级也不例外。

**还是不行**

有了更多使用 RX 的经验之后，我们可以很简单的解决 ComplerableFurue 的问题。重写代码，只使用 RX；在重写的过程中，升级到 RX2；真正的流式处理数据，而不是在内存里收集它们。这些改动通过 code review 之后，部署到开发环境进行测试。让我们吃惊的是，应用所需的内存丝毫没有减少。内存抽样显示，相较之前，内存中广告对象的数量有所减少。而且对象的数量现在不会一直增长，有时也会下降，因此他们不是全部在内存里收集的。还是老问题，看起来这些数据仍然没有真正的被归集成流。

**那现在是怎么回事？**

相关的关键词刚才已经提到了：背压。当数据被流式处理，生产者和消费者的速度不同是很正常的。如果生产者比消费者快，并且不能把速度降下来，它就会一直生产越来越多的数据，消费者无法以同样的速度处理掉他们。现象就是未处理数据的缓存不断增长，而这就是我们应用中真正发生的。背压就是一套机制，它允许一个较慢的消费者告诉较快的生产者去降速。

我们的索引系统没有背压的概念，这在之前没什么问题，反正我们把整个索引都保存到内存里了。一旦我们解决了之前的问题，开始真正的流式处理数据，缺少背压的问题就变得很明显了。

这个模式我在解决性能问题时见过很多次了：解决一个问题时会浮现另一个你甚至没有听说过的问题，因为其他问题把它隐藏起来了。如果你的房子经常被淹，你不会注意到它有火灾隐患。

**修复由修复引起的问题**

在 RxJava 2 里，原来的 Observable 类被拆成了不支持背压的 Observable 和支持背压的 Flowable。幸运的是，有一些简单的办法，可以开箱即用的把不支持背压的 Observable 改造成支持背压的 Flowable。其中包含从非响应式的资源比如 Iterable 创建 Flowable。把这些 Flowable 融合起来可以生成同样支持背压的 Flowable，因此只要快速解决一个点，整个系统就有了背压的支持。

有了这个改动之后，我们把堆从 12 GB 减少到了 3 GB ，同时让系统保持和之前同样的速度。我们仍然每隔数小时就会有一次暂停长达 2 秒的 full GC，不过这比我们之前见到的 20 秒的暂停（还有系统崩溃）要好多了。

**再次优化 GC**

但是，故事到此还没有结束。检查 GC 的日志，我们注意到大量的过早提升，占到 70%。尽管性能已经可以接受了，我们也尝试去解决这个问题，希望也许可以同时解决 full GC 的问题。

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/file/20190820104319.png)

如果一个对象的生命周期很短，但是它仍然晋升到了老年代，我们就把这种现象叫做过早提升（premature tenuring）（或者叫过早升级）。老年代里的对象通常都比较大，使用与新生代不同的 GC 算法，而这些过早提升的对象占据了老年代的空间，所以它们会影响 GC 的性能。因此，我们想竭力避免过早提升。

我们的应用在索引的过程中会产生大量短生命周期的对象，因此一些过早提升是正常的，但是不应该如此严重。当应用产生大量短生命周期的对象时，能想到的第一件事就是简单的增加新生代的空间。默认情况下，G1 的 GC 可以自动的调整新生代的空间，允许新生代使用堆内存的 5% 至 60%。我注意到运行的应用里，新生代和老年代的比例一直在一个很宽的幅度里变化，不过我依然动手修改了两个参数：-XX:G1NewSizePercent=40 和 -XX:G1MaxNewSizePercent=90看看会发生什么。这没起作用，甚至让事情变得更糟糕了，应用一启动就触发了 full GC。我也尝试了其他的比例，不过最好的情况就是只增加 G1MaxNewSizePercent而不修改最小值。这起了作用，大概和默认值的表现差不多，也没有变好。

尝试了很多办法后，也没有取得什么成就，我就放弃了，然后给 Kirk Pepperdine 发了封邮件。他是位很知名的 Java 性能专家，我碰巧在 Allegro 举办的 Devoxx 会议的训练课程里认识了他。通过查看 GC 的日志以及几封邮件的交流，Kirk 建议试试设置 -XX:G1MixedGCLiveThresholdPercent=100。这个设置应该会强制 G1 GC 在 mixed GC 时不去考虑它们被填充了多少，而是强制清理所有的老年代，因此也同时清理了从新生代过早提升的对象。这应该会阻止老年代被填满从而产生一次 full GC。然而，在运行一段时间以后，我们再次惊讶的发现了一次 full GC。Kirk 推断说他在其他应用里也见到过这种情况，它是 G1 GC 的一个 bug：mixed GC 显然没有清理所有的垃圾，让它们一直堆积直到产生 full GC。他说他已经把这个问题通知了 Oracle，不过他们坚称我们观察到的这个现象不是一个 bug，而是正常的。

**结论**

我们最后做的就是把应用的内存调大了一点点（从 3 GB 到 4 GB），然后 full GC 就消失了。我们仍然观察到大量的过早提升，不过既然性能是没问题的，我们就不在乎这些了。一个我们可以尝试的选项是转换到 GMS（Concurrent Mark Sweep）GC，不过由于它已经被废弃了，我们还是尽量不去使用它。



那么这个故事的寓意是什么呢？首先，性能问题很容易让你误入歧途。一开始看起来是 ZooKeeper 或者 网络的问题，最后发现是我们代码的问题。即使意识到了这一点，我首先采取的措施也没有考虑周全。为了防止 full GC，我在检查到底发生了什么之前就开始调优 GC。这是一个常见的陷阱，因此记住：即使你有一个直觉去做什么，先检查一下到底发生了什么，再检查一遍，防止浪费时间去错误的问题。

第二条，性能问题太难解决了。我们的代码有良好的测试覆盖率，而且运行的特别好，但是它也没有满足性能的要求，它在开始的时候就没有清晰的定义好。性能问题直到部署之后很久才浮现出来。由于通常很难真实的再现你的生产环境，你经常被迫在生产环境测试性能，即使那听起来非常糟糕。

第三条，解决一个问题有可能引发另一个潜在问题的浮现，强迫你不断挖的比你预想的更深。我们没有背压的事实足以中断这个系统，但是直到我们解决了内存泄漏的问题后，它才浮现。