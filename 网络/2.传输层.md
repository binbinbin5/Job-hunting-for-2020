[toc]

## 介绍
为进程提供通用数据传输服务。由于应用层协议很多，定义通用的传输层协议就可以支持不断增多的应用层协议。运输层包括两种协议：传输控制协议 TCP，提供面向连接、可靠的数据传输服务，数据单位为报文段；用户数据报协议 UDP，提供无连接、尽最大努力的数据传输服务，数据单位为用户数据报。TCP 主要提供完整性服务，UDP 主要提供及时性服务。

网络层只把分组发送到目的主机，但是真正通信的并不是主机而是主机中的进程。传输层提供了进程间的逻辑通信，传输层向高层用户屏蔽了下面网络层的核心细节，使应用程序看起来像是在两个传输层实体之间有一条端到端的逻辑通信信道。

### UDP 和 TCP 的特点

- 用户数据报协议 UDP（User Datagram Protocol）是无连接的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部），支持一对一、一对多、多对一和多对多的交互通信。
- 传输控制协议 TCP（Transmission Control Protocol）是面向连接的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流（把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块），每一条 TCP 连接只能是点对点的（一对一）。


1. 建立连接:是为了在客户端和服务端维护连接，而建立一定的数据结构来维护双方交互的状态，用这样的数据结构来保证所谓的面向连接的特性。

2. TCP提供可靠交付。通过TCP连接传输的数据，无差错、不丢失、不重复、并且按序到达。我们
都知道IP包是没有任何可靠性保证的，一旦发出去，就像西天取经，走丢了、被妖怪吃了，都只能随它去。但是TCP号称能做到那个连接维护的程序做的事情，这个下两节我会详细描述。而UDP继承了IP包
的特性，不保证不丢失，不保证按顺序到达。

3. TCP是面向字节流的。发送的时候发的是一个流，没头没尾。IP包可不是一个流，而是一个个
的IP包。之所以变成了流，这也是TCP自己的状态维护做的事情。而UDP继承了IP的特性，基于数据报
的，一个一个地发，一个一个地收。

4. TCP是可以有拥塞控制的。它意识到包丢弃了或者网络的环境不好了，就会根据情况调整自己的行
为，看看是不是发快了，要不要发慢点。UDP就不会，应用让我发，我就发，管它洪水滔天。

5. 因而TCP其实是一个有状态服务，通俗地讲就是有脑子的，里面精确地记着发送了没有，接收到没有，
发送到哪个了，应该接收哪个了，错一点儿都不行。而**UDP则是无状态服务。** 通俗地说是没脑子
的，天真无邪的，发出去就发出去了。

6. 如果MAC层定义了本地局域网的传输行为，IP层定义了整个网络端到端的传输行为，这两层基本定义了这样的基因：网络传输是以包为单位的，二层叫帧，网络层叫包，传输层叫段。我们笼统地称为包。包单独传输，自行选路，在不同的设备封装解封装，不保证到达。基于这个基因，生下来的孩子UDP完全继承了这些特性，几乎没有自己的思想。


在IP头里面有个8位协议，这里会存放，数据里面到底是TCP还是UDP。于是，如果我们知道TCP/UDP头的格式，就能从数据里面，将它解析出来。无论应用程序写的使用TCP传数据，还是UDP传数据，都要监听一个端口。正是这个端口，用来区分应用程序，要不说端口不能冲突呢。

两个应用监听一个端口，到时候包给谁呀？所以，按理说，无论是TCP还是UDP包头里面应该有端口号，根据端口号，将数据交给相应的应用程序。当我们看到UDP包头的时候，发现的确有端口号，有源端口号和目标端口号。

==TCP/IP或UDP/IP通信中通常采用5个信息来识别一个通信。它们是“源IP地址”、“目标IP地址”、“协议号”、“源端口号”、“目标端口号”。 只要其中某一项不同，则被认为是其他通信。==

### UDP 

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs20190601101405.png)

首部字段只有 8 个字节，包括源端口、目的端口、长度、检验和。12 字节的伪首部是为了计算检验和临时添加的。

特点：
- 第一，沟通简单，不需要一肚子花花肠子（大量的数据结构、处理逻辑、包头字段）。前提是它相信网
- 络世界是美好的，秉承性善论，相信网络通路默认就是很容易送达的，不容易被丢弃的。
- 第二，轻信他人。它不会建立连接，虽然有端口号，但是监听在这个地方，谁都可以传给他数据，他也可以传给任何人数据，甚至可以同时传给多个人数据。
- 第三，愣头青，做事不懂权变。不知道什么时候该坚持，什么时候该退让。它不会根据网络的情况进行发包的拥塞控制，无论网络丢包丢成啥样了，它该怎么发还怎么发

使用场景：
1. 第一，需要资源少，在网络情况比较好的内网，或者对于丢包不敏感的应用。这很好理解，就像如果你是领导，你会让你们组刚毕业的小朋友去做一些没有那么难的项目，打一些没有那么难的客户，或者做一些失败了也能忍受的实验性项目。

    DHCP就是基于UDP协议的。一般的获取IP地址都是内网请求，而且一次获取不
到IP又没事，过一会儿还有机会。我们讲过PXE可以在启动的时候自动安装操作系统，操作系统镜像的
下载使用的TFTP，这个也是基于UDP协议的。在还没有操作系统的时候，客户端拥有的资源很少，不
适合维护一个复杂的状态机，而是因为是内网，一般也没啥问题。


2. 第二，不需要一对一沟通，建立连接，而是可以广播的应用。咱们小时候人都很简单，大家在班级里面，谁成绩好，谁写作好，应该表扬谁惩罚谁，谁得几个小红花都是当着全班的面讲的，公平公正公开。长大了人心复杂了，薪水、奖金要背靠背，和员工一对一沟通。

3. 第三，需要处理速度快，时延低，可以容忍少数丢包，但是要求即便网络拥塞，也毫不退缩，一往无前的时候。记得曾国藩建立湘军的时候，专门招出生牛犊不怕虎的新兵，而不用那些“老油条”的八旗兵，就是因为八旗兵经历的事情多，遇到敌军不敢舍死忘生。


同理，UDP简单、处理速度快，不像TCP那样，操这么多的心，各种重传啊，保证顺序啊，前面的不收
到，后面的没法处理啊。不然等这些事情做完了，时延早就上去了。而TCP在网络不好出现丢包的时
候，拥塞控制策略会主动的退缩，降低发送速度，这就相当于本来环境就差，还自断臂膀，用户本来就卡，这下更卡了。

当前很多应用都是要求低时延的，它们可不想用TCP如此复杂的机制，而是想根据自己的场景，实现自
己的可靠和连接保证。例如，如果应用自己觉得，有的包丢了就丢了，没必要重传了，就可以算了，有的比较重要，则应用自己重传，而不依赖于TCP。有的前面的包没到，后面的包到了，那就先给客户展示后面的嘛，干嘛非得等到齐了呢？如果网络不好，丢了包，那不能退缩啊，要尽快传啊，速度不能降下来啊，要挤占带宽，抢在客户失去耐心之前到达。


>应用：网页APP访问（QUIC）/流媒体协议（直播）/实时游戏/物联网/移动通信

### TCP 
TCP除了做流量控制以外，TCP还会做拥塞控制。

TCP是靠谱的协议，但是这不能说明它面临的网络环境好。从IP层面来讲，如果网络状况的确那么差，
是没有任何可靠性保证的，而作为IP的上一层TCP也无能为力，唯一能做的就是更加努力，不断重传，
通过各种算法保证。也就是说，对于TCP来讲，IP层你丢不丢包，我管不着，但是我在我的层面上，会
努力保证可靠性。

- 顺序问题 ，稳重不乱；
- 丢包问题，承诺靠谱；
- 连接维护，有始有终；
- 流量控制，把握分寸；
- 拥塞控制，知进知退。


![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs20190601101432.png)
- 源端口号和目标端口号是不可少的，这一点和UDP是一样的。如果没有这两个端口号。数据就不
知道应该发给哪个应用。
- **序号**  ：为了解决乱序的问题。用于对字节流进行编号，例如序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401。
- **确认号**  ：如果没有收
到就应该重新发送，直到送达。这个可以解决不丢包的问题。期望收到的下一个报文段的序号。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。
- **数据偏移**  ：指的是数据部分距离报文段起始处的偏移量，实际上指的是首部的长度。
- **确认 ACK**  ：当 ACK=1 时确认号字段有效，否则无效。TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 置 1。
- **同步 SYN**  ：在连接建立时用来同步序号。当 SYN=1，ACK=0 时表示这是一个连接请求报文段。若对方同意建立连接，则响应报文中 SYN=1，ACK=1。
- **终止 FIN**  ：用来释放一个连接，当 FIN=1 时，表示此报文段的发送方的数据已发送完毕，并要求释放连接。
- **窗口**  ：窗口值作为接收方让发送方设置其发送窗口的依据。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。

#### TCP 的三次握手
SYN是发起一个连接，ACK是回复，RST是重新连接，FIN是结束连接等。TCP是面向连接的，因而双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变。

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs/20190527142901.png)

假设 A 为客户端，B 为服务器端。

- 首先 B 处于 LISTEN（监听）状态，等待客户的连接请求。
- A 向 B 发送连接请求报文，SYN=1，ACK=0，选择一个初始的序号 x。
- B 收到连接请求报文，如果同意建立连接，则向 A 发送连接确认报文，SYN=1，ACK=1，确认号为 x+1，同时也选择一个初始的序号 y。
- A 收到 B 的连接确认报文后，还要向 B 发出确认，确认号为 y+1，序号为 x+1。
- B 收到 A 的确认后，连接建立。

**三次握手的原因** 


第三次握手是为了防止失效的连接请求到达服务器，让服务器错误打开连接。

好在大部分情况下，A和B建立了连接之后，A会马上发送数据的，一旦A发送数据，则很多问题都得到
了解决。例如A发给B的应答丢了，当A后续发送的数据到达的时候，B可以认为这个连接已经建立，或
者B压根就挂了，A发送的数据，会报错，说B不可达，A就知道B出事情了。

当然你可以说A比较坏，就是不发数据，建立连接后空着。我们在程序设计的时候，可以要求开
启keepalive机制，即使没有真实的数据包，也有探活包。

另外，你作为服务端B的程序设计者，对于A这种长时间不发包的客户端，可以主动关闭，从而空出资
源来给其他客户端使用。


三次握手除了双方建立连接外，主要还是为了沟通一件事情，就是TCP包的序号的问题。A要告诉B，我这面发起的包的序号起始是从哪个号开始的，B同样也要告诉A，B发起的包的序号起始是
从哪个号开始的。为什么序号不能都从1开始呢？因为这样往往会出现冲突。

>例如，A连上B之后，发送了1、2、3三个包，但是发送3的时候，中间丢了，或者绕路了，于是重新发
送，后来A掉线了，重新连上B后，序号又从1开始，然后发送2，但是压根没想发送3，但是上次绕路的
那个3又回来了，发给了B，B自然认为，这就是下一个包，于是发生了错误。因而，每个连接都要有不同的序号。这个序号的起始序号是随着时间变化的，可以看成一个32位的计数器，每4ms加一，如果计算一下，如果到重复，需要4个多小时，那个绕路的包早就死翘翘了，因为我们都知道IP包头里面有个TTL，也即生存时间。

#### TCP 的四次挥手

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs/20190527142959.png)

以下描述不讨论序号和确认号，因为序号和确认号的规则比较简单。并且不讨论 ACK，因为 ACK 在连接建立之后都为 1。

- A 发送连接释放报文，FIN=1。
- B 收到之后发出确认，此时 TCP 属于半关闭状态，B 能向 A 发送数据但是 A 不能向 B 发送数据。
- 当 B 不再需要连接时，发送连接释放报文，FIN=1。
- A 收到后发出确认，进入 TIME-WAIT 状态，等待 2 MSL（最大报文存活时间）后释放连接。
- B 收到 A 的确认后释放连接。

**四次挥手的原因** 

客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态。这个状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送 FIN 连接释放报文。

**TIME_WAIT** 

客户端接收到服务器端的 FIN 报文后进入此状态，此时并不是直接进入 CLOSED 状态，还需要等待一个时间计时器设置的时间 2MSL。这么做有两个理由：

- 确保最后一个确认报文能够到达。如果 B 没收到 A 发送来的确认报文，那么就会重新发送连接释放请求报文，A 等待一段时间就是为了处理这种情况的发生。
- 等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文。

#### TCP状态机
将连接建立和连接断开的两个时序状态图综合起来，就是这个著名的TCP的状态机。

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs20190601173601.png)

#### TCP 可靠传输

TCP ==++使用超时重传来实现可靠传输++==：如果一个已经发送的报文段在超时时间内没有收到确认，那么就重传这个报文段。

一个报文段从发送再到接收到确认所经过的时间称为往返时间 RTT，加权平均往返时间 RTTs 计算如下：

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs20190601101739.png)

其中，0 ≤ a ＜ 1，RTTs 随着 a 的增加更容易受到 RTT 的影响。

超时时间 RTO 应该略大于 RTTs，TCP 使用的超时时间计算如下：

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs20190601101759.png)

其中 RTT<sub>d</sub> 为偏差的加权平均值。



#### TCP 滑动窗口
TCP以一个段为单位，每发一个段进行确认这样通信性能比较低，所以采用一种叫窗口的概念，不是每个分段发送，而是以更大的单位发送，转发时间缩短：

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs20190601180237.png)



++TCP协议为了保证顺序性，每一个包都有一个ID。在建立连接的时候，会商定
起始的ID是什么，然后按照ID一个个发送++。++为了保证不丢包，对于发送的包都要进行应答，但是这个应
答也不是一个一个来的，而是会应答某个之前的ID，表示都收到了，这种模式称为累计确认或者累计应答（cumulative acknowledgment）++。




为了记录所有发送的包和接收的包，TCP也需要发送端和接收端分别都有缓存来保存这些记录。发送端
的缓存里是按照包的ID一个个排列，根据处理的情况分成四个部分。
- 第一部分：发送了并且已经确认的。
- 第二部分：发送了并且尚未确认的。
- 第三部分：没有发送，但是已经等待发送的。
- 第四部分：没有发送，并且暂时还不会发送的。

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs20190601173642.png)
- LastByteAcked：第一部分和第二部分的分界线
- LastByteSent：第二部分和第三部分的分界线
- LastByteAcked + AdvertisedWindow：第三部分和第四部分的分界线

对于接收端来讲，它的缓存里记录的内容要简单一些。
- 第一部分：接受并且确认过的。
- 第二部分：还没接收，但是马上就能接收的。也即是我自己的能够接受的最大工作量。
- 第三部分：还没接收，也没法接收的。也即超过工作量的部分，实在做不完。


![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs20190601173732.png)

- MaxRcvBuffer：最大缓存的量；
- LastByteRead之后是已经接收了，但是还没被应用层读取的；
- NextByteExpected是第一部分和第二部分的分界线。

>第二部分的窗口有多大呢？
NextByteExpected和LastByteRead的差其实是还没被应用层读取的部分占用掉的MaxRcvBuffer的量


##### 重发控制
使用窗口控制的时候，丢失数据怎么办？

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs20190601184009.png)

没有使用窗口，丢失的数据会重发，使用了窗口，某些确认应答丢失也不需重发，而是确认丢失之后，同一个序号将不断的返回，如果发送端连续收到三次同一个确认应答，将会对其进行数据重发，这称作为==高速重发控制==。

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs20190601184403.png)

##### 流量控制

流量控制是为了控制发送方发送速率，保证接收方来得及接收。

++接收方发送的确认TCP首部专有一个字段来通知窗口大小++。报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs20190601184608.png)

上图到3001的时候数据段的缓冲区满了，不得不暂停发送，之后，在收到发送窗口更新通知后继续进行。但没事如果更新通知丢失，则无法更新，所以发送端将会时不时发送窗口探测的数据段。

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs20190601173906.png)

这个时候，假设发送端发送过猛，会将第三部分的10、11、12、13全部发送完毕，之后就停止发送了，
未发送可发送部分为0

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs20190601173920.png)

当对于包5的确认到达的时候，在客户端相当于窗口再滑动了一格，这个时候，才可以有更多的包可以
发送了，例如第14个包才可以发送。

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs20190601173933.png)

如果接收方实在处理的太慢，导致缓存中没有空间了，可以通过确认信息修改窗口的大小，甚至可以设置为0，则发送方将暂时停止发送。

我们假设一个极端情况，接收端的应用一直不读取缓存中的数据，当数据包6确认后，窗口大小就不能
再是9了，就要缩小一个变为8。

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs20190601173953.png)

这个新的窗口8通过6的确认消息到达发送端的时候，你会发现窗口没有平行右移，而是仅仅左面的边右移了，窗口的大小从9改成了8

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs20190601174037.png)

如果接收端还是一直不处理数据，则随着确认的包越来越多，窗口越来越小，直到为0。

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs20190601174052.png)

当这个窗口通过包14的确认到达发送端的时候，发送端的窗口也调整为0，停止发送。

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs20190601174112.png)

如果这样的话，发送方会定时发送窗口探测数据包，看是否有机会调整窗口的大小。当接收方比较慢的时候，要防止低能窗口综合征，别空出一个字节来就赶快告诉发送方，然后马上又填满了，可以当窗口太小的时候，不更新窗口，直到达到一定大小，或者缓冲区一半为空，才更新窗口。






##### 拥塞控制

计算机网络处于共享环境，因此也有可能会因为其他主机之间的通信导致网络拥堵，如果这时候发送大量数据则会导致网络瘫痪。如果接受端空闲，网络也空闲，那么我们可以增加发送量使得速度变快。


---

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs20190601174150.png)

如图所示，假设往返时间为8s，去4s，回4s，每秒发送一个包，每个包1024byte。已经过去了8s，
则8个包都发出去了，其中前4个包已经到达接收端，但是ACK还没有返回，不能算发送成功。5-8后四
个包还在路上，还没被接收。这个时候，整个管道正好撑满，在发送端，已发送未确认的为8个包，正
好等于带宽，也即每秒发送1个包，乘以来回时间8s。

如果我们在这个基础上再调大窗口，使得单位时间内更多的包可以发送，会出现什么现象呢？

我们来想，原来发送一个包，从一端到达另一端，假设一共经过四个设备，每个设备处理一个包时间耗费1s，所以到达另一端需要耗费4s，如果发送的更加快速，则单位时间内，会有更多的包到达这些中间设备，这些设备还是只能每秒处理一个包的话，多出来的包就会被丢弃，这是我们不想看到的。

这个时候，我们可以想其他的办法，例如这个四个设备本来每秒处理一个包，但是我们在这些设备上加缓存，处理不过来的在队列里面排着，这样包就不会丢失，但是缺点是会增加时延，这个缓存的
包，4s肯定到达不了接收端了，如果时延达到一定程度，就会超时重传，也是我们不想看到的。



###### 慢开始 快重传
于是TCP的拥塞控制主要来避免两种现象，包丢失和超时重传。一旦出现了这些现象就说明，发送速度
太快了，要慢一点。但是一开始我怎么知道速度多快呢，我怎么知道应该把窗口调整到多大呢？

如果我们通过漏斗往瓶子里灌水，我们就知道，不能一桶水一下子倒进去，肯定会溅出来，要一开始慢慢的倒，然后发现总能够倒进去，就可以越倒越快。这叫作慢开始。

一条TCP连接开始，cwnd设置为一个报文段，一次只能发送一个；当收到这一个确认的时候，cwnd加
一，于是一次能够发送两个；当这两个的确认到来的时候，每个确认cwnd加一，两个确认cwnd加二，
于是一次能够发送四个；当这四个的确认到来的时候，每个确认cwnd加一，四个确认cwnd加四，于是
一次能够发送八个。可以看出这是指数性的增长。

涨到什么时候是个头呢？有一个值ssthresh为65535个字节，当超过这个值的时候，就要小心一点了，
不能倒这么快了，可能快满了，再慢下来。
每收到一个确认后，cwnd增加1/cwnd，我们接着上面的过程来，一次发送八个，当八个确认到来的时
候，每个确认增加1/8，八个确认一共cwnd增加1，于是一次能够发送九个，变成了线性增长。

但是线性增长还是增长，还是越来越多，直到有一天，水满则溢，出现了拥塞，这时候一般就会一下子降低倒水的速度，等待溢出的水慢慢渗下去。

拥塞的一种表现形式是丢包，需要超时重传，这个时候，将sshresh设为cwnd/2，将cwnd设为1，重新
开始慢启动。这真是一旦超时重传，马上回到解放前。但是这种方式太激进了，将一个高速的传输速度一下子停了下来，会造成网络卡顿。


---

当接收端发现丢了一个中间包的时候，发送三次前一个包的ACK，于是发
送端就会快速的重传，不必等待超时再重传。TCP认为这种情况不严重，因为大部分没丢，只丢了一小
部分，cwnd减半为cwnd/2，然后sshthresh = cwnd，当三个包返回的时候，cwnd = sshthresh + 3，
也就是没有一夜回到解放前，而是还在比较高的值，呈线性增长

在接收方，要求每次接收到报文段都应该对最后一个已收到的有序报文段进行确认。例如已经接收到 M<sub>1</sub> 和 M<sub>2</sub>，此时收到 M<sub>4</sub>，应当发送对 M<sub>2</sub> 的确认。

在发送方，如果收到三个重复确认，那么可以知道下一个报文段丢失，此时执行快重传，立即重传下一个报文段。例如收到三个 M<sub>2</sub>，则 M<sub>3</sub> 丢失，立即重传 M<sub>3</sub>。

在这种情况下，只是丢失个别报文段，而不是网络拥塞。因此执行快恢复，令 ssthresh = cwnd / 2 ，cwnd = ssthresh，注意到此时直接进入拥塞避免。

慢开始和快恢复的快慢指的是 cwnd 的设定值，而不是 cwnd 的增长速率。慢开始 cwnd 设定为 1，而快恢复 cwnd 设定为 ssthresh。

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs20190601101900.png)

TCP的拥塞控制主要来避免的两个现象都是有问题的：
- 第一个问题是丢包并不代表着通道满了，也可能是管子本来就漏水。例如公网上带宽不满也会丢包，这
个时候就认为拥塞了，退缩了，其实是不对的。
- 第二个问题是TCP的拥塞控制要等到将中间设备都填充满了，才发生丢包，从而降低速度，这时候已经
晚了。其实TCP只要填满管道就可以了，不应该接着填，直到连缓存也填满。

为了优化这两个问题，后来有了TCP BBR拥塞算法。它企图找到一个平衡点，就是通过不断的加快发
送速度，将管道填满，但是不要填满中间设备的缓存，因为这样时延会增加，在这个平衡点可以很好的
达到高带宽和低时延的平衡。

#### 顺序和丢包问题

结合一个例子来看，在发送端来看，1、2、3已经发送并确认；4、5、6、7、8、9都是发送了还没确
认；10、11、12是还没发出的；13、14、15是接收方没有空间，不准备发的。

在接收端来看，1、2、3、4、5是已经完成ACK，但是没读取的；6、7是等待接收的；8、9是已经接
收，但是没有ACK的。
发送端和接收端当前的状态如下：
- 1、2、3没有问题，双方达成了一致。
- 4、5接收方说ACK了，但是发送方还没收到，有可能丢了，有可能在路上。
- 6、7、8、9肯定都发了，但是8、9已经到了，但是6、7没到，出现了乱序，缓存着但是没办法ACK。

根据这个例子，我们可以知道，顺序问题和丢包问题都有可能发生，所以我们先来看确认与重发的机
制。

>假设4的确认到了，不幸的是，5的ACK丢了，6、7的数据包丢了，这该怎么办呢？

一种方法就是超时重试，也即对每一个发送了，但是没有ACK的包，都有设一个定时器，超过了一定的
时间，就重新尝试。但是这个超时的时间如何评估呢？这个时间不宜过短，时间必须大于往返时
间RTT，否则会引起不必要的重传。也不宜过长，这样超时时间变长，访问就变慢了。

估计往返时间，需要TCP通过采样RTT的时间，然后进行加权平均，算出一个值，而且这个值还是要不
断变化的，因为网络状况不断的变化。除了采样RTT，还要采样RTT的波动范围，计算出一个估计的超
时时间。由于重传时间是不断变化的，我们称为自适应重传算法（Adaptive Retransmission
Algorithm）。

如果过一段时间，5、6、7都超时了，就会重新发送。接收方发现5原来接收过，于是丢弃5；6收到
了，发送ACK，要求下一个是7，7不幸又丢了。当7再次超时的时候++，有需要重传的时候，TCP的策略
是超时间隔加倍。每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍++。两次超时，就说明网络环境差，不宜频繁反复发送。
超时触发重传存在的问题是，超时周期可能相对较长。那是不是可以有更快的方式呢？

有一个可以快速重传的机制，当接收方收到一个序号大于下一个所期望的报文段时，就检测到了数据流中的一个间格，于是发送三个冗余的ACK，客户端收到后，就在定时器过期之前，重传丢失的报文段。

例如，接收方发现6、8、9都已经接收了，就是7没来，那肯定是丢了，于是发送三个6的ACK，要求下
一个是7。客户端收到3个，就会发现7的确又丢了，不等超时，马上重发。

还有一种方式称为Selective Acknowledgment （SACK）。这种方式需要在TCP头里加一个SACK的
东西，可以将缓存的地图发送给发送方。例如可以发送ACK6、SACK8、SACK9，有了地图，发送方一
下子就能看出来是7丢了.