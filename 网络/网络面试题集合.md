[toc]

# 网络为什么要分层
==分层使得每层都有每层的作用和范围，使得面向的问题不同，解决的事情不同，让整个过程都比较清晰和简单化。分层的本质是通过分离关注点而让问题简单化。==

当一个系统足够复杂时，通过聚合分为不同层次， 每层都是内聚的，对外屏蔽复杂性。 那么宏观上看去，管理和问题定位很容易到具体层次。 然后层层递进，很容易定位问题。 
 

1. 只关注整个结构中的其中某一层,它只需要知道通过与底层的接口就可以获得所需要的服务；
2. 可以很容易的用新的实现来替换原有层次的实现
3. 可以降低层与层之间的依赖
4. 使得复杂的计算机网络系统变得易于设计，实现和标准化
5. 利于各层逻辑的复用


## Cookoie和token的区别
①：token和cookie一样都是首次登陆时，由服务器下发，都是当交互时进行验证的功能，作用都是为无状态的HTTP提供的持久机制。

②：token存在哪儿都行，localstorage或者cookie。

③：token和cookie举例，token就是说你告诉我你是谁就可以。

```
cookie 举例：服务员看你的身份证，给你一个编号，以后，进行任何操作，都出示编号后服务员去看查你是谁。
token  举例：直接给服务员看自己身份证
```

④：对于token而言，服务器不需要去查看你是谁，不需要保存你的会话。当用户logout的时候cookie和服务器的session都会注销；但是当logout时候token只是注销浏览器信息，不查库。

⑤：token优势在于，token由于服务器端不存储会话，所以可扩展性强，token还可用于APP中。

```
总结：

Token 完全由应用管理，所以它可以避开同源策略
Token 可以避免 CSRF 攻击
Token 可以是无状态的，可以在多个服务间共享

如果你的用户数据可能需要和第三方共享，或者允许第三方调用 API 接口，用 Token，如果之上自己的那就无所谓了。 
```


## 查看ip地址的命令


```
ifconfig -all: mac/Linux

ipconfig -all: windows
```




## MTU是什么

最大传输单元。

由于不同硬件的物理特性不同，对数据帧的最大长度都有不同的限制，这个最大长度称为MTU。

## 常用端口以及对应服务

| **常见服务** | **端口**      |
| ------------ | ------------- |
| HTTP         | 80            |
| FTP          | 21            |
| DNS          | 53            |
| POP3         | 110           |
| SMTP         | 25            |
| SSH          | 22            |
| nginx        | 80            |
| MEMCACHED    | 11211         |
| MYSQL        | 3306          |
| TOMCAT       | 8080          |
| NFS          | 2049          |
| TLENET       | 23            |
| HTTPS        | 443           |
| SAMBA        | UDP139 TCP139 |
| POSTFIX      | 25            |
| IMAP         | 143           |
| ZABBIX       | 10051         |
| DHCP         | 56            |

## 层数和协议
7层模型（物理层，数据链入层，网络层，传输层，会话层，表示层，应用层）

4层协议（网络接口层，网际层，传输层，应用层）

**5层模型**

1. 应用层：**完成应用之间的通信和交互**

   1. **HTTP/HTTPS**:超文本传输协议，网络传输协议
   2. **DNS**: 域名解析协议，将域名和IP地址映射
   3. SMTP：邮件传输协议
   4. POP3 和 IMAP：邮件读取协议常用
   5. **DHCP**：动态主机配置协议
   6. FTP:文件传送协议
   7. TELNET：远程登录协议

2. 传输层：**解决数据间的传输**

   1. **TCP**:面向连接，可靠的传输协议
   2. **UDP**：无连接，不可靠的传输协议

3. 网络层:**网络地址翻译成物理地址，决定如何将数据发送到接收方**

   1. **IP**:**互联网协议地址**
   2. ICMP:网际控制报文协议
   3. IGMP：网际组管理协议
   4. OSPF: 内部网关协议
   5. BGP:外部网关协议 

4. 数据链入层：**主机之间的数据传输服务，数据链路层把网络层传下来的分组封装成帧**

   1. **ARP**:IP地址解析为物理地址

   2. RARP:物理地址解析为IP地址

   3. CSMA/CD 协议：（多点接入载波监听碰撞检测）一对多通信协议

   4. **PPP协议**：点对点连接上传输多协议数据包提供了一个标准方法

   5. **STP**:生成树协议

5. 物理层：**实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异**

其他：
1. 物理层：RJ45、CLOCK、IEEE802.3 （中继器，集线器，网关）
1. 数据链路：PPP、FR、HDLC、VLAN、MAC （网桥，交换机）
1. 网络层：IP、ICMP、ARP、RARP、OSPF、IPX、RIP、IGRP、 （路由器）
1. 传输层：TCP、UDP、SPX
1. 会话层：NFS、SQL、NETBIOS、RPC
1. 表示层：JPEG、MPEG、ASII
1. 应用层：FTP、DNS、Telnet、SMTP、HTTP、WWW、NFS

## 数据在各层之间的传递过程
在向下的过程中，需要添加下层协议所需要的首部或者尾部，而在向上的过程中不断拆开首部和尾部。

路由器只有下面三层协议，因为路由器位于网络核心中，不需要为进程或者应用程序提供服务，因此也就不需要传输层和应用层。

## 路由器和交换机的区别？
1. 路由器可以给你的局域网自动分配IP，虚拟拨号，就像一个交通警察，指挥着你的电脑该往哪走，你自己不用操心那么多了。交换机只是用来分配网络数据的。交换机用来共享一根网线，路由器用来共享一个IP。



2. 路由器在网络层，路由器可以处理TCP/IP协议，交换机不可以，交换机在中继层。路由器根据IP地址寻址，交换机根据MAC地址寻址。



3. 路由器可以把一个IP分配给很多个主机使用，这些主机对外只表现出一个IP。交换机可以把很多主机连起来，这些主机对外各有各的IP。



4. 路由器提供防火墙的服务，具有虚拟拨号上网功能，交换机不具备这些功能。



5. 集线器、交换机都是做端口扩展的，就是扩大局域网(通常都是以太网)的接入点，也就是能让局域网可以连进来更多的电脑。路由器是用来做网间连接，也就是用来连接不同的网络。交换机构成局域网，路由器构成广域网。

# DNS

## 流程
1. 在浏览器中输入 www.qq.com 域名，操作系统会先检查自己本地的 hosts 文件是否有这个
网址映射关系，如果有，就先调用这个 IP 地址映射，完成域名解析。
2. 如果 hosts 里没有这个域名的映射，则查找本地 DNS 解析器缓存，是否有这个网址映射
关系，如果有，直接返回，完成域名解析。
3. 如果 hosts 与本地 DNS 解析器缓存都没有相应的网址映射关系，首先会找 TCP/ip 参数中
设置的首选 DNS 服务器，在此我们叫它本地 DNS 服务器，此服务器收到查询时，如果要查询的域
名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。
4. 如果要查询的域名，不由本地 DNS 服务器区域解析，但该服务器已缓存了此网址映射关
系，则调用这个 IP 地址映射，完成域名解析，此解析不具有权威性。
5. 如果本地 DNS 服务器本地区域文件与缓存解析都失效，则根据本地 DNS 服务器的设置（是
否设置转发器）进行查询，如果未用转发模式，本地 DNS 就把请求发至 13 台根 DNS，根 DNS 服
务器收到请求后会判断这个域名(.com)是谁来授权管理，并会返回一个负责该顶级域名服务器的
一个 IP。本地 DNS 服务器收到 IP 信息后，将会联系负责.com 域的这台服务器。这台负责.com
域的服务器收到请求后，如果自己无法解析，它就会找一个管理.com 域的下一级 DNS 服务器地
址(qq.com)给本地 DNS 服务器。当本地 DNS 服务器收到这个地址后，就会找 qq.com 域服务器，
重复上面的动作，进行查询，直至找到 www.qq.com 主机。
6. 如果用的是转发模式，此 DNS 服务器就会把请求转发至上一级 DNS 服务器，由上一级服
务器进行解析，上一级服务器如果不能解析，或找根 DNS 或把转请求转至上上级，以此循环。不
管是本地 DNS 服务器用是是转发，还是根提示，最后都是把结果返回给本地 DNS 服务器，由此
DNS 服务器再返回给客户机。

从客户端到本地 DNS 服务器是属于递归查询，而 DNS 服务器之间就是的交互查询就是迭代查
询。
![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs20190602104004.png)
## 负载均衡反向代理模式优点及缺点
反向代理:
- （1）反向代理（Reverse Proxy）方式是指以代理服务器来接受 internet 上的连接请求，然
后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给 internet 上请求连接
的客户端，此时代理服务器对外就表现为一个服务器。
- （2）反向代理负载均衡技术是把将来自 internet 上的连接请求以反向代理的方式动态地转
发给内部网络上的多台服务器进行处理，从而达到负载均衡的目的。
- （3）反向代理负载均衡能以软件方式来实现，如 apache mod_proxy、netscape proxy 等，
也可以在高速缓存器、负载均衡器等硬件设备上实现。反向代理负载均衡可以将优化的负载均衡
策略和代理服务器的高速缓存技术结合在一起，提升静态网页的访问速度，提供有益的性能；由
于网络外部用户不能直接访问真实的服务器，具备额外的安全性（同理，NAT 负载均衡技术也有
此优点）。
- （4）其缺点主要表现在以下两个方面
    - 反向代理是处于 OSI 参考模型第七层应用的，所以就必须为每一种应用服务专门开发一个反
向代理服务器，这样就限制了反向代理负载均衡技术的应用范围，现在一般都用于对 web 服务器
的负载均衡。
    - 针对每一次代理，代理服务器就必须打开两个连接，一个对外，一个对内，因此在并发连接
请求数量非常大的时候，代理服务器的负载也就非常大了，在最后代理服务器本身会成为服务的
瓶颈。一般来讲，可以用它来对连接数量不是特别大，但每次连接都需要消耗大量处理资源的站点
进行负载均衡，如 search 等。

# HTTP
## 请求头 请求行 请求体
![](https://raw.githubusercontent.com/binbinbin5/myPics/master/file/20190925230132.png)

请求行
- ①是请求方法，GET和POST是最常见的HTTP方法，除此以外还包括DELETE、HEAD、OPTIONS、PUT、TRACE。
- ②为请求对应的URL地址，它和报文头的Host属性组成完整的请求URL。
- ③是协议名称及版本号。

请求头：
- ④是HTTP的报文头，报文头包含若干个属性，格式为“属性名:属性值”，服务端据此获取客户端的信息。

请求体：
- ⑤是报文体

## 特点

1. 简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。

2. 灵活：HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。

3. 无连接：==无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接==。采用这种方式可以节省传输时间。

4. 无状态：HTTP协议是无状态协议。==无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大==。另一方面，在服务器不需要先前信息时它的应答就较快。
5. 支持B/S及C/S模式。

## HTTP1.0和HTTP1.1的一些区别
  - 增加长连接
  - 增加宽带优化和网络连接的使用
  - 错误通知的管理：增加错误状态的影响码
  - Host头处理：一台主机多个虚拟主机，头处理可以准确定位
  - 缓存处理：引用更多控制策略

## HTTP 2.0 和 HTTP1.1 区别
  - **多路复用技术**:1.1是一来一去的请求响应，2.0是可多次请求发送多次响应接收。比如发送Hello和world。1.1是一次发送hello一次发送world。2.0是1h 2w 1e 2o 1l 1l 2 r 2l 1o 2d 这样发送。单连接多资源的方式，减少服务端的链接压力,内存占用更少,连接吞吐量更大；由于减少TCP 慢启动时间，提高传输的速度。
  - **首部压缩**：页面产生的请求数也越来越多，导致消耗在头部的流量越来越多，尤其是每次都要传输 UserAgent、Cookie 这类不会频繁变动的内容，完全是一种浪费。压缩就会减少资源。
  - **服务器推送**：在它响应浏览器第一个请求的时候，可以开始推送这些资源。这允许服务端去完全充分地利用一个可能空闲的网络，改善页面加载时间。（一次请求,HTTP,CSS,JP,IMG一同接收）



## 管线化pipelining

持久连接使得多数请求以管线化（pipelining）方式发送成为可能。从前发送请求后需等待并收到响应，才能 发送下一个请求。管线化技术出现后，==不用等待响应亦可直接发送下一个请求==。

这样就能够做到同时并行发送多个请求，而不需要一个接一个地等待响应了。通俗地讲，请求打包一次传输过去，响应打包一次传递回来。管线化的前提是在持久连接下。

于是在使用持久连接的情况下，某个连接上消息的传递类似于：


```
请求1 -> 响应1 -> 请求2 -> 响应2 -> 请求3 -> 响应3

管线化方式发送变成了类似这样：

请求1 -> 请求2 -> 请求3 -> 响应1 -> 响应2 -> 响应3
```
## 通信传输流


![](https://github.com/zaiyunduan123/Java-Interview/blob/master/image/network-1.png)


发送端在层与层之间传输数据时，每经过一层时必定会被打上一个该层所属的首部信息。反之，接收端在层与层传输数据时，每经过一层时会把对应的首部消去

ARP 是一种用以解析地址的协议，根据通信方的 IP 地址就可以反查出对应的 MAC 地址。

## 各种协议与HTTP协议的关系

![](https://github.com/zaiyunduan123/Java-Interview/blob/master/image/network-2.png)



## 长连接和短链接（HTTP是基于TCP）
  - 长连接：==传输开始就建立连接，连接一直存在，期间可以进行多次传输，直到关闭，多是客户端关闭连接。== 长连接可以省去较多的TCP建立和关闭的操作，减少浪费，节约时间。但是每次都新建一个连接，当连接过多时server负担过重。长连接多用于操作频繁，点对点的通讯，而且连接数不能太多情况，比如数据库连接，网游连接。(HTTP1.1以上存在长连接)
  
  - 短链接：==每传输一次就建立连接，传输完毕就断开连接==。优点是管理起来比较简单，存在的连接都是有用的连接，不需要额外的控制手段。缺点是每次建立开端都需要资源时间消耗。短链接多用于连接数据量比较大的情况，比如网站WEB连接。（HTTP1.0）

## 影响一个 HTTP 网络请求的因素
  - 带宽：影响网速
  - 延迟：浏览器阻塞，建立TCP连接时间长，DNS查询慢


## 状态码
| 状态码 | 类别 | 含义 |
| :---: | :---: | :---: |
| 1XX | Informational（信息性状态码） | 接收的请求正在处理 |
| 2XX | Success（成功状态码） | 请求正常处理完毕 |
| 3XX | Redirection（重定向状态码） | 需要进行附加操作以完成请求 |
| 4XX | Client Error（客户端错误状态码） | 服务器无法处理请求 |
| 5XX | Server Error（服务器错误状态码） | 服务器处理请求出错 |
-  200 OK                        //客户端请求成功
- 301 Moved Permanently   //永久重定向,使用域名跳转
- 302 Found                                         //  临时重定向,未登陆的用户访问用户中心重定向到登录页面
- 400 Bad Request               //客户端请求有语法错误，不能被服务器所理解
- 401 Unauthorized              //请求未经授权，这个状态代码必须和WWW-Authenticate报头域一起使用 
- 403 Forbidden                 //服务器收到请求，但是拒绝提供服务
- 404 Not Found                 //请求资源不存在，eg：输入了错误的URL
- 500 Internal Server Error     //服务器发生不可预期的错误
- 503 Server Unavailable        //服务器当前不能处理客户端的请求，一段时间后可能恢复正常

## http 响应码 301 和 302 代表的是什么？有什么区别？

```
301：永久重定向。
302：暂时重定向。
```
它们的区别是，301 对搜索引擎优化（SEO）更加有利；302 有被提示为网络拦截的风险。

## forward 和 redirect 的区别？
forward 是转发 和 redirect 是重定向：
- 地址栏 url 显示：foward url 不会发生改变，redirect url 会发生改变；
- 数据共享：forward 可以共享 request 里的数据，redirect 不能共享；
- 效率：forward 比 redirect 效率高。

## HTTP方法

1. get:客户端向服务端发起请求，获得资源。请求获得URL处所在的资源
2. post:向服务端提交新的请求字段。请求URL的资源后添加新的数据
3. head:请求获取URL资源的响应报告，即获得URL资源的头部
4. patch：请求局部修改URL所在资源的数据项
5. put：请求修改URL所在资源的数据元素
6. delete：请求删除url资源的数据




## GET和POST区别
**GET请求不安全，但是GET请求速度快，一次产生一个数据包，而POST则两个，所以请求数据一般用get，提交数据一般用post。**
### GET



请注意，查询字符串（名称/值对）是在 GET 请求的 URL 中发送的：
```
/test/demo_form.asp?name1=value1&name2=value2
```

1. GET 请求可被缓存
2. GET 请求保留在浏览器历史记录中
3. GET 请求可被收藏为书签
4. GET 请求不应在处理敏感数据时使用
5. GET 请求有长度限制（浏览器通常都会限制url长度在2K个字节，而(大多数)服务器最多处理64K大小的url）
6. GET 请求只应当用于取回数据
7. GET产生一个TCP数据包（对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200(返回数据)）
8. GET操作符合数据库幂等性和安全性（对数据库一个操作和多次操作获得同一结果，安全性是没有改变数据库）
### POST
请注意，查询字符串（名称/值对）是在 POST 请求的 HTTP 消息主体中发送的：
```
POST /test/demo_form.asp HTTP/1.1
Host: w3schools.com
name1=value1&name2=value2
```
1. POST 请求不会被缓存
2. POST 请求不会保留在浏览器历史记录中
3. POST 不能被收藏为书签
4. POST 请求对数据长度没有要求
5. POST产生两个TCP数据包（对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok(返回数据)）
6. POST对数据库不安全 

### 相同点
HTTP的底层是TCP/IP。所以GET和POST的底层也是TCP/IP，也就是说，GET/POST都是TCP链接。GET和POST能做的事情是一样的。你要给GET加上request body，给POST带上url参数，技术上是完全行的通的。




## 一次完整的HTTP请求过程
域名解析 --> 发起TCP的3次握手 --> 建立TCP连接后发起http请求 --> 服务器响应http请求，浏览器得到html代码 --> 浏览器解析html代码，并请求html代码中的资源（如js、css、图片等） --> 浏览器对页面进行渲染呈现给用户




## HTTPS和HTTP的区别
1. https协议需要到CA申请证书，一般免费证书很少，需要交费。
2. http是超文本传输协议，信息是明文传输；https 则是具有安全性的ssl加密传输协 议。
3. http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。
4. http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。
5. http默认使用80端口，https默认使用443端口


## HTTP的缺点
1. 通信使用明文（不加密） ， 内容可能会被窃听
2. 不验证通信方的身份， 因此有可能遭遇伪装
3. 无法证明报文的完整性， 所以有可能已遭篡改

## 现代浏览器在与服务器建立了一个 TCP 连接后是否会在一个 HTTP 请求完成后断开？什么情况下会断开？

==默认开启持久连接，只有在请求报头中声明 Connection: close 才会在请求完成后关闭连接==

在 HTTP/1.0 中，一个服务器在发送完一个 HTTP 响应后，会断开 TCP 链接。但是这样每次请求都会重新建立和断开 TCP 连接，代价过大。所以虽然标准中没有设定，某些服务器对 Connection: keep-alive 的 Header 进行了支持。

意思是说，完成这个 HTTP 请求之后，不要断开 HTTP 请求使用的 TCP 连接。这样的好处是连接可以被重新使用，之后发送 HTTP 请求的时候不需要重新建立 TCP 连接，以及如果维持连接，那么 SSL 的开销也可以避免。

持久连接：既然维持 TCP 连接好处这么多，HTTP/1.1 就把 Connection 头写进标准，并且默认开启持久连接，除非请求中写明 Connection: close，那么浏览器和服务器之间是会维持一段时间的 TCP 连接，不会一个请求结束就断掉。

## 一个 TCP 连接可以对应几个 HTTP 请求？
如果维持连接，一个 TCP 连接是可以发送多个 HTTP 请求的。
## 一个 TCP 连接中 HTTP 请求发送可以一起发送么（比如一起发三个请求，再三个响应一起接收）？
在 HTTP/1.1 存在 Pipelining 技术可以完成这个多个请求同时发送，但是由于浏览器默认关闭，所以可以认为这是不可行的。在 HTTP2 中由于 ==多路复用== 特点的存在，多个 HTTP 请求可以在同一个 TCP 连接中并行进行。

那么在 HTTP/1.1 时代，浏览器是如何提高页面加载效率的呢？主要有下面两点：

- 维持和服务器已经建立的 TCP 连接，在同一连接上顺序处理多个请求。
- 和服务器建立多个 TCP 连接。

## 为什么有的时候刷新页面不需要重新建立 SSL 连接？

TCP 连接有的时候会被浏览器和服务端维持一段时间。TCP 不需要重新建立，SSL 自然也会用之前的。

## 浏览器对同一 Host 建立 TCP 连接到数量有没有限制？

假设我们还处在 HTTP/1.1 时代，那个时候没有多路传输，当浏览器拿到一个有几十张图片的网页该怎么办呢？肯定不能只开一个 TCP 连接顺序下载，那样用户肯定等的很难受，但是如果每个图片都开一个 TCP 连接发 HTTP 请求，那电脑或者服务器都可能受不了，要是有 1000 张图片的话总不能开 1000 个TCP 连接吧，你的电脑同意 NAT 也不一定会同意。

所以答案是：==有。Chrome 最多允许对同一个 Host 建立六个 TCP 连接。不同的浏览器有一些区别。==

## 收到的 HTML 如果包含几十个图片标签，这些图片是以什么方式、什么顺序、建立了多少连接、使用什么协议被下载下来的呢？

如果图片都是 HTTPS 连接并且在同一个域名下，那么浏览器在 SSL 握手之后会和服务器商量能不能用 HTTP2，如果能的话就使用 Multiplexing 功能在这个连接上进行多路传输。不过也未必会所有挂在这个域名的资源都会使用一个 TCP 连接去获取，但是可以确定的是 Multiplexing 很可能会被用到。

如果发现用不了 HTTP2 呢？或者用不了 HTTPS（现实中的 HTTP2 都是在 HTTPS 上实现的，所以也就是只能使用 HTTP/1.1）。那浏览器就会在一个 HOST 上建立多个 TCP 连接，连接数量的最大限制取决于浏览器设置，这些连接会在空闲的时候被浏览器用来发送新的请求，如果所有的连接都正在发送请求呢？那其他的请求就只能等等了。


## HTTP是无状态协议
HTTP 协议自身不具备保存之前发送过的请求或响应的功能，这是为了更快地处理大量事务，确保协议的可伸缩性，而特意把 HTTP 协议设计成如此简单的。

HTTP/1.1 虽然是无状态协议，但为了实现期望的保持状态功能，于是引入了 Cookie 技术。有了 Cookie 再用 HTTP 协议通信，就可以管理状态了。

## HTTP是不保存状态的协议,如何保存用户状态?

HTTP 是一种不保存状态，即无状态（stateless）协议。也就是说 HTTP  协议自身不对请求和响应之间的通信状态进行保存。那么我们保存用户状态呢？Session 机制的存在就是为了解决这个问题，Session 的主要作用就是通过服务端记录用户的状态。典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了（一般情况下，服务器会在一定时间内保存这个 Session，过了时间限制，就会销毁这个Session）。

在服务端保存 Session 的方法很多，最常用的就是内存和数据库(比如是使用内存数据库redis保存)。既然 Session 存放在服务器端，那么我们如何实现 Session 跟踪呢？大部分情况下，我们都是通过在 Cookie 中附加一个 Session ID 来方式来跟踪。

**Cookie 被禁用怎么办?**

最常用的就是利用 URL 重写把 Session ID 直接附加在URL路径的后面。

![HTTP是无状态协议](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/HTTP是无状态的.png)

## Cookie Session Token
http无状态，为了使某个域名下的所有网页能够共享某些数据，session和cookie出现了

Cookie
- 客户端向服务器请求的时候会产生一个cookie返回客户端
- 当客户端再次进行请求的时候就会把cookie放对象头传过去
- 服务器接受的时候会解析产生客户端相同的内容，验证信息，核对成功后返回给客户端

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/file/20190722205913.png)

- a、session是一种服务器端的状态管理技术。
- b、session是基于cookie的技术。
- c、当浏览器访问服务器时，服务器会创建一个session对象（该对象有一个唯一的id号，称之为sessionId）服务器在默认的情况下，会将sessionId以cookie的方式，发送给浏览器，浏览器会将sessionId保存到内存中。当浏览器再次访问服务器时，会将sessionId发送给服务器，服务器依据sessionId就可以找到之间创建的session对象。

Session:
- session是一门服务端会话缓存技术。
- session由服务器端的web容器创建，保存在服务器端。
- session保存数据：键值对形式
- session过期：默认30分钟

session是服务端的会话技术，当用户登录了系统，服务器端的web容器就会创建一个会话，此会话中可以保存登录用户的信息，并且也是以键值对的形式去保存的，现在大部分系统都是使用的session技术来做的鉴权（权限鉴定），即：当用户登录完了才可以访问系统中的一些页面和数据。   

Session 实现：
 1. cookie
 2. url回写
 

token的意思是“令牌”，是服务端生成的一串字符串，作为客户端进行请求的一个标识。

当用户第一次登录后，服务器生成一个token并将此token返回给客户端，以后客户端只需带上这个token前来请求数据即可，无需再次带上用户名和密码。

token 的认证流程与cookie很相似

- 用户登录，成功后服务器返回Token给客户端。
- 客户端收到数据后保存在客户端
- 客户端再次访问服务器，将token放入headers中
- 服务器端采用filter过滤器校验。校验成功则返回请求数据，校验失败则返回错误码

### token可以抵抗csrf，cookie+session不行
假如用户正在登陆银行网页，同时登陆了攻击者的网页，并且银行网页未对csrf攻击进行防护。攻击者就可以在网页放一个表单，该表单提交src为http://www.bank.com/api/transfer，body为count=1000&to=Tom。倘若是session+cookie，用户打开网页的时候就已经转给Tom1000元了.因为form 发起的 POST 请求并不受到浏览器同源策略的限制，因此可以任意地使用其他域的 Cookie 向其他域发送 POST 请求，形成 CSRF 攻击。在post请求的瞬间，cookie会被浏览器自动添加到请求头中。但token不同，token是开发者为了防范csrf而特别设计的令牌，浏览器不会自动添加到headers里，攻击者也无法访问用户的token，所以提交的表单无法通过服务器过滤，也就无法形成攻击。

### 分布式情况下的session和token
我们已经知道session时有状态的，一般存于服务器内存或硬盘中，当服务器采用分布式或集群时，session就会面对负载均衡问题。

负载均衡多服务器的情况，不好确认当前用户是否登录，因为多服务器不共享session。这个问题也可以将session存在一个服务器中来解决，但是就不能完全达到负载均衡的效果。当今的几种解决session负载均衡的方法。

而token是无状态的，token字符串里就保存了所有的用户信息

客户端登陆传递信息给服务端，服务端收到后把用户信息加密（token）传给客户端，客户端将token存放于localStroage等容器中。客户端每次访问都传递token，服务端解密token，就知道这个用户是谁了。通过cpu加解密，服务端就不需要存储session占用存储空间，就很好的解决负载均衡多服务器的问题了。这个方法叫做JWT(Json Web Token)

### 总结
- session存储于服务器，可以理解为一个状态列表，拥有一个唯一识别符号sessionId，通常存放于cookie中。服务器收到cookie后解析出sessionId，再去session列表中查找，才能找到相应session。依赖cookie
- cookie类似一个令牌，装有sessionId，存储在客户端，浏览器通常会自动添加。
- token也类似一个令牌，无状态，用户信息都被加密到token中，服务器收到token后解密就可知道是哪个用户。需要开发者手动添加。
- jwt只是一个跨域认证的方案

注意
- cookie只是实现session的其中一种方案。虽然是最常用的，但并不是唯一的方法。禁用cookie后还有其他方法存储，比如放在url中
- 现在大多都是Session + Cookie，但是只用session不用cookie，或是只用cookie，不用session在理论上都可以保持会话状态。可是实际中因为多种原因，一般不会单独使用
- 用session只需要在客户端保存一个id，实际上大量数据都是保存在服务端。如果全部用cookie，数据量大的时候客户端是没有那么多空间的。
- 如果只用cookie不用session，那么账户信息全部保存在客户端，一旦被劫持，全部信息都会泄露。并且客户端数据量变大，网络传输的数据量也会变大




## Cookie的作用是什么?和Session有什么区别？

Cookie 和 Session都是用来跟踪浏览器用户身份的会话方式，但是两者的应用场景不太一样。

 **Cookie 一般用来保存用户信息** 比如①我们在 Cookie 中保存已经登录过得用户信息，下次访问网站的时候页面可以自动帮你登录的一些基本信息给填了；②一般的网站都会有保持登录也就是说下次你再访问网站的时候就不需要重新登录了，这是因为用户登录的时候我们可以存放了一个 Token 在 Cookie 中，下次登录的时候只需要根据 Token 值来查找用户即可(为了安全考虑，重新登录一般要将 Token 重写)；③登录一次网站后访问网站其他页面不需要重新登录。
 
 **Session 的主要作用就是通过服务端记录用户的状态。** 典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了。

Cookie 数据保存在客户端(浏览器端)，Session 数据保存在服务器端。

Cookie 存储在客户端中，而Session存储在服务器上，相对来说 Session 安全性更高。如果使用 Cookie 的一些敏感信息不要写入 Cookie 中，最好能将 Cookie 信息加密然后使用到的时候再去服务器端解密。

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/file/20190722213115.png)

## Cookie

HTTP 协议是无状态的，主要是为了让 HTTP 协议尽可能简单，使得它能够处理大量事务。HTTP/1.1 引入 Cookie 来保存状态信息。

Cookie 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器之后向同一服务器再次发起请求时被携带上，用于告知服务端两个请求是否来自同一浏览器。由于之后每次请求都会需要携带 Cookie 数据，因此会带来额外的性能开销（尤其是在移动环境下）。

Cookie 曾一度用于客户端数据的存储，因为当时并没有其它合适的存储办法而作为唯一的存储手段，但现在随着现代浏览器开始支持各种各样的存储方式，Cookie 渐渐被淘汰。新的浏览器 API 已经允许开发者直接将数据存储到本地，如使用 Web storage API（本地存储和会话存储）或 IndexedDB。

### 1. 用途

- 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息）
- 个性化设置（如用户自定义设置、主题等）
- 浏览器行为跟踪（如跟踪分析用户行为等）

### 2. 创建过程

服务器发送的响应报文包含 Set-Cookie 首部字段，客户端得到响应报文后把 Cookie 内容保存到浏览器中。

```html
HTTP/1.0 200 OK
Content-type: text/html
Set-Cookie: yummy_cookie=choco
Set-Cookie: tasty_cookie=strawberry

[page content]
```

客户端之后对同一个服务器发送请求时，会从浏览器中取出 Cookie 信息并通过 Cookie 请求首部字段发送给服务器。

```html
GET /sample_page.html HTTP/1.1
Host: www.example.org
Cookie: yummy_cookie=choco; tasty_cookie=strawberry
```

### 3. 分类

- 会话期 Cookie：浏览器关闭之后它会被自动删除，也就是说它仅在会话期内有效。
- 持久性 Cookie：指定过期时间（Expires）或有效期（max-age）之后就成为了持久性的 Cookie。

```html
Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT;
```

### 4. 作用域

Domain 标识指定了哪些主机可以接受 Cookie。如果不指定，默认为当前文档的主机（不包含子域名）。如果指定了 Domain，则一般包含子域名。例如，如果设置 Domain=mozilla.org，则 Cookie 也包含在子域名中（如 developer.mozilla.org）。

Path 标识指定了主机下的哪些路径可以接受 Cookie（该 URL 路径必须存在于请求 URL 中）。以字符 %x2F ("/") 作为路径分隔符，子路径也会被匹配。例如，设置 Path=/docs，则以下地址都会匹配：

- /docs
- /docs/Web/
- /docs/Web/HTTP

### 5. JavaScript

浏览器通过 `document.cookie` 属性可创建新的 Cookie，也可通过该属性访问非 HttpOnly 标记的 Cookie。

```html
document.cookie = "yummy_cookie=choco";
document.cookie = "tasty_cookie=strawberry";
console.log(document.cookie);
```

### 6. HttpOnly

标记为 HttpOnly 的 Cookie 不能被 JavaScript 脚本调用。跨站脚本攻击 (XSS) 常常使用 JavaScript 的 `document.cookie` API 窃取用户的 Cookie 信息，因此使用 HttpOnly 标记可以在一定程度上避免 XSS 攻击。

```html
Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Secure; HttpOnly
```

### 7. Secure

标记为 Secure 的 Cookie 只能通过被 HTTPS 协议加密过的请求发送给服务端。但即便设置了 Secure 标记，敏感信息也不应该通过 Cookie 传输，因为 Cookie 有其固有的不安全性，Secure 标记也无法提供确实的安全保障。

### 8. Session

除了可以将用户信息通过 Cookie 存储在用户浏览器中，也可以利用 Session 存储在服务器端，存储在服务器端的信息更加安全。

Session 可以存储在服务器上的文件、数据库或者内存中。也可以将 Session 存储在 Redis 这种内存型数据库中，效率会更高。

使用 Session 维护用户登录状态的过程如下：

- 用户进行登录时，用户提交包含用户名和密码的表单，放入 HTTP 请求报文中；
- 服务器验证该用户名和密码，如果正确则把用户信息存储到 Redis 中，它在 Redis 中的 Key 称为 Session ID；
- 服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID，客户端收到响应报文之后将该 Cookie 值存入浏览器中；
- 客户端之后对同一个服务器进行请求时会包含该 Cookie 值，服务器收到之后提取出 Session ID，从 Redis 中取出用户信息，继续之前的业务操作。

应该注意 Session ID 的安全性问题，不能让它被恶意攻击者轻易获取，那么就不能产生一个容易被猜到的 Session ID 值。此外，还需要经常重新生成 Session ID。在对安全性要求极高的场景下，例如转账等操作，除了使用 Session 管理用户状态之外，还需要对用户进行重新验证，比如重新输入密码，或者使用短信验证码等方式。





## 缓存

### 1. 优点

- 缓解服务器压力；
- 降低客户端获取资源的延迟：缓存通常位于内存中，读取缓存的速度更快。并且缓存服务器在地理位置上也有可能比源服务器来得近，例如浏览器缓存。

### 2. 实现方法

- 让代理服务器进行缓存；
- 让客户端浏览器进行缓存。

### 3. Cache-Control

HTTP/1.1 通过 Cache-Control 首部字段来控制缓存。

**3.1 禁止进行缓存** 

no-store 指令规定不能对请求或响应的任何一部分进行缓存。

```html
Cache-Control: no-store
```

**3.2 强制确认缓存** 

no-cache 指令规定缓存服务器需要先向源服务器验证缓存资源的有效性，只有当缓存资源有效时才能使用该缓存对客户端的请求进行响应。

```html
Cache-Control: no-cache
```

**3.3 私有缓存和公共缓存** 

private 指令规定了将资源作为私有缓存，只能被单独用户使用，一般存储在用户浏览器中。

```html
Cache-Control: private
```

public 指令规定了将资源作为公共缓存，可以被多个用户使用，一般存储在代理服务器中。

```html
Cache-Control: public
```

**3.4 缓存过期机制** 

max-age 指令出现在请求报文，并且缓存资源的缓存时间小于该指令指定的时间，那么就能接受该缓存。

max-age 指令出现在响应报文，表示缓存资源在缓存服务器中保存的时间。

```html
Cache-Control: max-age=31536000
```

Expires 首部字段也可以用于告知缓存服务器该资源什么时候会过期。

```html
Expires: Wed, 04 Jul 2012 08:26:05 GMT
```

- 在 HTTP/1.1 中，会优先处理 max-age 指令；
- 在 HTTP/1.0 中，max-age 指令会被忽略掉。

### 4. 缓存验证

需要先了解 ETag 首部字段的含义，它是资源的唯一标识。URL 不能唯一表示资源，例如 `http://www.google.com/` 有中文和英文两个资源，只有 ETag 才能对这两个资源进行唯一标识。

```html
ETag: "82e22293907ce725faf67773957acd12"
```

可以将缓存资源的 ETag 值放入 If-None-Match 首部，服务器收到该请求后，判断缓存资源的 ETag 值和资源的最新 ETag 值是否一致，如果一致则表示缓存资源有效，返回 304 Not Modified。

```html
If-None-Match: "82e22293907ce725faf67773957acd12"
```

Last-Modified 首部字段也可以用于缓存验证，它包含在源服务器发送的响应报文中，指示源服务器对资源的最后修改时间。但是它是一种弱校验器，因为只能精确到一秒，所以它通常作为 ETag 的备用方案。如果响应首部字段里含有这个信息，客户端可以在后续的请求中带上 If-Modified-Since 来验证缓存。服务器只在所请求的资源在给定的日期时间之后对内容进行过修改的情况下才会将资源返回，状态码为 200 OK。如果请求的资源从那时起未经修改，那么返回一个不带有实体主体的 304 Not Modified 响应报文。

```html
Last-Modified: Wed, 21 Oct 2015 07:28:00 GMT
```

```html
If-Modified-Since: Wed, 21 Oct 2015 07:28:00 GMT
```

## 内容协商

通过内容协商返回最合适的内容，例如根据浏览器的默认语言选择返回中文界面还是英文界面。




# HTTPS

HTTPS 并非是应用层的一种新协议。 只是 HTTP 通信接口部分用SSL（Secure Socket Layer） 和 TLS（Transport Layer Security） 协议代替而已。

通常， HTTP 直接和 TCP 通信。 当使用 SSL时， 则演变成先和 SSL通信， 再由 SSL和 TCP 通信了。 简言之， 所谓 HTTPS， 其实就是身披SSL协议这层外壳的 HTTP。

SSL是独立于 HTTP 的协议， 所以不光是 HTTP 协议， 其他运行在应用层的 SMTP 和 Telnet 等协议均可配合 SSL协议使用。 可以说 SSL是当今世界上应用最为广泛的网络安全技术

## https是如何保证数据传输的安全
https实际就是在TCP层与http层之间加入了SSL/TLS来为上层的安全保驾护航，主要用到对称加密、非对称加密、证书，等技术进行客户端与服务器的数据加密传输，最终达到保证整个通信的安全性。

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/file/20190722213319.png)


### SSL/TLS

1. SSL 是“Secure Sockets Layer”的缩写，中文叫做“安全套接层”
2. 因为原先互联网上使用的HTTP协议是明文的，存在很多缺点——比如传输内容会被偷窥（嗅探）和篡改。发明 SSL 协议，就是为了解决这些问题。
   SSL 因为应用广泛，IETF 就把 SSL 标准化。标准化之后的名称改为 TLS（是“Transport Layer Security”的缩写），中文叫做“传输层安全协议”。所以两个是没区别的


**SSL/TLS作用**
1. 认证用户和服务器，确保数据发送到正确的客户机和服务器；
2. 加密数据以防止数据中途被窃取；
3. 维护数据的完整性，确保数据在传输过程中不被改变。

![](https://github.com/zaiyunduan123/Java-Interview/blob/master/image/network-1.jpg)

## HTTPS工作流程
![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs/20190722124243.png)

1. Client发起一个HTTPS（https:/demo.linianhui.dev）的请求，根据RFC2818的规定，Client知道需要连接Server的443（默认）端口。
1. Server把事先配置好的把公钥放在证书里发送给客户端，私钥自己保存
1. Client验证公钥证书：比如是否在有效期内，证书的用途是不是匹配Client请求的站点，是不是在CRL吊销列表里面，它的上一级证书是否有效，这是一个递归的过程，直到验证到根证书（操作系统内置的Root证书或者Client内置的Root证书）。如果验证通过则继续，不通过则显示警告信息。
1. Client使用伪随机数生成器生成加密所使用的会话密钥，然后用证书的公钥加密这个会话密钥，发给Server。
1. Server使用自己的私钥（private key）解密这个消息，得到会话密钥。至此，Client和Server双方都持有了相同的会话密钥。
1. Server使用会话密钥加密“明文内容A”，发送给Client。
1. Client使用会话密钥解密响应的密文，得到“明文内容A”。
1. Client再次发起HTTPS的请求，使用会话密钥加密请求的“明文内容B”，然后Server使用会话密钥解密密文，得到“明文内容B”。


# IP
## 为什么有IP地址还需要MAC地址

- 只拥有MAC地址的话，只有在同一网络区域内，才能进行数据传输，不能跨网络区域。
- 如果想跨网络区域进行数据传递，最现实的方法就是借助ISP提供的网络区域。
- ISP能提供全球互联的网络——因特网，借助因特网可以传输数据给连接因特网上的机器。

IP可以保证要发送的包在网络中传输，到达目标服务器所在的局域网的网关。
但是到了网关后，IP就没用了，因为局域网的IP对应的机器是不确定的，可能今天对应A机器，明天对应B机器。
所以在局域网中使用IP寻址是不严谨的，这时就需要MAC地址来唯一对应一台机器，这样网络包就可以准确的传输到需要的主机上了
## IP地址的分类
A类地址：以0开头，第一个字节范围：0~127（1.0.0.0 - 126.255.255.255)；

B类地址：以10开头，第一个字节范围：128~191（128.0.0.0 - 191.255.255.255);

C类地址：以110开头，第一个字节范围：192~223（192.0.0.0 - 223.255.255.255);

内部地址：10.0.0.0—10.255.255.255， 172.16.0.0—172.31.255.255， 192.168.0.0—192.168.255.255。

## 子网掩码的作用
子网掩码只有一个作用，就是将某个IP地址划分成网络地址和主机地址两部分。


## 网关

为了简化问题，假设两个网关直连

网关收到这个包后（因为mac地址是它的），打开一看IP地址是 11.239.161.60，不是自己的，于是继续查自己的route和arp缓存，发现11.239.161.60这个IP的网关是11.239.163.247，于是把包的目的mac地址改成11.239.163.247的mac继续发出去。

11.239.163.247这个网关收到包后，一看 11.239.161.60是自己同一子网的IP，于是该arp广播找mac就广播，cache有就拿cache的，然后这个包才最终到达目的11.239.161.60上。

整个过程中目标mac地址每一跳都在变，IP地址不变，每经过一次MAC变化可以简单理解成一跳。

实际上可能要经过多个网关多次跳跃才能真正到达目标机器。


## 怎么查看IP地址吗？

- Windows : ipconifg 
- Linux/Mac : ifconfig/ipaddr

## 如何配置IP地址？

```
//使用net-tools：

$ sudo ifconfig eth1 10.0.0.1/24
$ sudo ifconfig eth1 up

//使用iproute2：

$ sudo ip addr add 10.0.0.1/24 dev eth1
$ sudo ip link set up eth1
```
自己配置这个自由度太大了吧，我是不是配置什么都可以？如果配置一个和谁都不搭边的地址呢？例如，旁边的机器都是192.168.1.x，我非得配置一个16.158.23.6，会出现什么现象呢？

不会出现任何现象，就是包发不出去呗。为什么发不出去呢？

虽然它有自己的源IP地址16.158.23.6，也有目标IP地址192.168.1.6，但是包发不出去，这是因为MAC层还没填。
++只要是在网络上跑的包，都是完整的，可以有下层没上层，绝对不可能有上层没下层。++

当发出信息的时候，Linux首先会判断，要去的这个地址和我是一个网段的吗，或者和我的一个网卡是同一网段的吗？只有是一个网段的，它才会发送ARP请求，获取MAC地址。如果发现不是呢？

++Linux默认的逻辑是，如果这是一个跨网段的调用，它便不会直接将包发送到网络上，而是企图将包发送到网关。++

如果你配置了网关的话，Linux会获取网关的MAC地址，然后将包发出去。对于192.168.1.6这台机器来讲，虽然路过它家门的这个包，目标IP是它，但是无奈MAC地址不是它的，所以它的网卡是不会把包收进去的。

如果没有配置网关呢？那包压根就发不出去。

如果将网关配置为192.168.1.6呢？不可能，Linux不会让你配置成功的，因为++网关要和当前的网络至少一个网卡是同一个网段的++，怎么可能16.158.23.6的网关是192.168.1.6呢？

配置IP的时候，不同系统的配置文件格式不同，但是无非就是CIDR、子网掩码、广播地址和网关地址。


## net-tools和iproute2的“历史”故事
- net-tools起源于BSD，自2001年起，Linux社区已经对其停止维护，而iproute2旨在取代net-tools，并提供了一些新功能。一些Linux发行版已经停止支持net-tools，只支持iproute2。
- net-tools通过procfs(/proc)和ioctl系统调用去访问和改变内核网络配置，++而iproute2则通过netlink套接字接口与内核通讯++。
- net-tools中工具的名字比较杂乱，++而iproute2则相对整齐和直观，基本是ip命令加后面的子命令++。


## IPF类型
IP地址是一个网卡在网络世界的通讯地址，相当于我们现实世界的门牌号码。

例子：
10.100.122.2就是一个IP地址。这个地址被点分隔为四个部分，每个部分8个bit，所以IP地址总共是32位。
![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs20190529213224.png)
### IPV4和IPV6
这样产生的IP地址的数量很快就不够用了。因为当时设计IP地址的时候，哪知道今天会有这么多的计算机啊！因为不够用，于是就有了IPv6，也就是上面输出结果里面inet6 fe80::f816:3eff:fec7:7975/64。这个有128位，现在看来是够了，但是未来的事情谁知道呢？

本来32位的IP地址就不够，还被分成了5类。现在想想，当时分配地址的时候，真是太奢侈了：
![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs/20190529192817.png)


```
A 0.0.0.0 - 127.255.255.255
B 128.0.0.0 - 191.255.255.255
C 192.0.0.0 - 223.255.255.255
D 224.0.0.0 - 239.255.255.255  组播
E 240.0.0.0 - 255.255.255.255  保留 
```

B类168.195.0.0分成27个子网
```
27个子网 2^5=27
子网掩码255.255.11111000.0 = 255.255.248.0
```


在网络地址中，至少在当时设计的时候，对于A、B、 C类主要分两部分，前面一部分是网络号，后面一部分是主机号。

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs/20190529192853.png)
这里面有个尴尬的事情，就是C类地址能包含的最大主机数量实在太少了，只有254个。当时设计的时候恐怕没想到，现在估计一个网吧都不够用吧。而B类地址能包含的最大主机数量又太多了。6万多台机器放在一个网络下面，一般的企业基本达不到这个规模，闲着的地址就是浪费。

### 无类型域间选路（CIDR）

行的IPv4（网际协议第4版）的地址已经耗尽，这是一种为解决地址耗尽而提出的一种措施。它是将好几个IP网络结合在一起，使用一种无类别的域际路由选择算法，可以减少由核心路由器运载的路由选择信息的数量。

IP地址的32位是由网络号+主机号组成的，也就是说这32位中，左边的某些连续位表示网络号，右边的某些连续位表示主机号

CIDR。++这种方式打破了原来设计的几类地址的做法，将32位的IP地址一分为二，前面是网络号，后面是主机号++。它真正消除了传统的A类、B类、C类地址以及划分子网的概念。

>10.100.122.2/24从哪里分呢？

这个IP地址中有一个斜杠，斜杠后面有个数字24。这种地址表示形式，就是CIDR。后面24的意思是，32位中，前24位是网络号，后8位是主机号。


```
地址数：可以分配32-24=8 2^8=254台主机（包括0和1）

最小地址：10.100.122.00000000
最大地址：10.100.122.11111111
子网掩码：255.255.255.0（前24位1，后8位0）


//将子网掩码和IP地址按位计算AND，就可得到网络号

255.255.255.0 | 10.100.122.2 = 10.100.122.0

网络号：10.100.122.0

聚合C类网的数量 2^8 / 2^8 =1

```

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs20190529213649.png)



### 公有IP地址和私有IP地址

在日常的工作中，几乎不用划分A类、B类或者C类，所以时间长了，很多人就忘记了这个分类，而只记得CIDR。但是有一点还是要注意的，就是公有IP地址和私有IP地址。

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs/20190529193109.png)

表格最右列是私有IP地址段。平时我们看到的数据中心里，办公室、家里或学校的IP地址，一般都是私有IP地址段。++因为这些地址允许组织内部的IT人员自己管理、自己分配，而且可以重复++。因此，你学校的某个私有IP地址段和我学校的可以是一样的。

公有IP地址有个组织统一分配，你需要去买。如果你搭建一个网站，给你学校的人使用，让你们学校的IT人员给你一个IP地址就行。但是假如你要做一个类似网易163这样的网站，就需要有公有IP地址，这样全世界的人才能访问。

表格中的192.168.0.x是最常用的私有IP地址。你家里有Wi-Fi，对应就会有一个IP地址。一般你家里地上网设备不会超过256个，所以/24基本就够了。有时候我们也能见到/16的CIDR，这两种是最常见的，也是最容易理解的。

不需要将十进制转换为二进制32位，就能明显看出192.168.0是网络号，后面是主机号。而整个网络里面的第一个地址192.168.0.1，往往就是你这个私有网络的出口地址。例如，你家里的电脑连接Wi-Fi，Wi-Fi路由器的地址就是192.168.0.1，而192.168.0.255就是广播地址。一旦发送这个地址，整个192.168.0网络里面的所有机器都能收到。

### 一个容易“犯错”的CIDR

16.158.165.91/22这个CIDR。求一下这个网络的第一个地址、子网掩码和广播地址。

/22不是8的整数倍，不好办，只能先变成二进制来看。16.158的部分不会动，它占了前16位。中间的165，变为二进制为‭10100101‬。除了前面的16位，还剩6位。所以，这8位中前6位是网络号，16.158.<101001>，而<01>.91是机器号。

第一个地址是16.158.<101001><00>.1，即16.158.164.1。子网掩码是255.255.<111111><00>.0，即255.255.252.0。广播地址为16.158.<101001><11>.255，即16.158.167.255。

这五类地址中，还有一类D类是组播地址。使用这一类地址，属于某个组的机器都能收到。这有点类似在公司里面大家都加入了一个邮件组。发送邮件，加入这个组的都能收到。组播地址在后面讲述VXLAN协议的时候会提到。

### DHCP协议有什么作用
一个局域网的网络协议，使用UDP协议工作，用途：给内部网络或网络服务供应商自动分配IP地址，给用户或者内部网络管理员作为对所有计算机作中央管理的手段。


#### 解析DHCP的工作方式


当一台机器新加入一个网络的时候，肯定一脸懵，啥情况都不知道，只知道自己的MAC地址。这时候他接触网络，这一步，我们称为DHCP Discover。比如：新来的机器使用IP地址0.0.0.0发送了一个广播包，目的IP地址为255.255.255.255。广播包封装了UDP，UDP封装了BOOTP。其实DHCP是BOOTP的增强版，但是如果你去抓包的话，很可能看到的名称还是BOOTP协议。

在这个广播包里面，新人大声喊：我是新来的（Boot request），我的MAC地址是这个，我还没有IP，谁能给租给我个IP地址！![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs/20190529194542.png)

如果一个网络管理员在网络里面配置了DHCP Server的话，他就相当于这些IP的管理员。他立刻能知道来了一个“新人”。这个时候，我们可以体会MAC地址唯一的重要性了。当一台机器带着自己的MAC地址加入一个网络的时候，MAC是它唯一的身份，如果连这个都重复了，就没办法配置了。

只有MAC唯一，IP管理员才能知道这是一个新人，需要租给它一个IP地址，这个过程我们称为DHCP Offer。同时，DHCP Server为此客户保留为它提供的IP地址，从而不会为其他DHCP客户分配此IP地址。

DHCP Offer的格式就像这样，里面有给新人分配的地址。

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs/20190529194617.png)

DHCP Server仍然使用广播地址作为目的地址，因为，此时请求分配IP的新人还没有自己的IP。DHCP Server回复说，我分配了一个可用的IP给你，你看如何？除此之外，服务器还发送了子网掩码、网关和IP地址租用期等信息。

如果有多个DHCP Server，这台新机器会收到多个IP地址，简直受宠若惊。它会选择其中一个DHCP Offer，一般是最先到达的那个，并且会向网络发送一个DHCP Request广播数据包，包中包含客户端的MAC地址、接受的租约中的IP地址、提供此租约的DHCP服务器地址等，并告诉所有DHCP Server它将接受哪一台服务器提供的IP地址，告诉其他DHCP服务器，谢谢你们的接纳，并请求撤销它们提供的IP地址，以便提供给下一个IP租用请求者。

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs/20190529194659.png)

此时，由于还没有得到DHCP Server的最后确认，客户端仍然使用0.0.0.0为源IP地址、255.255.255.255为目标地址进行广播。在BOOTP里面，接受某个DHCP Server的分配的IP。

当DHCP Server接收到客户机的DHCP request之后，会广播返回给客户机一个DHCP ACK消息包，表明已经接受客户机的选择，并将这一IP地址的合法租用信息和其他的配置信息都放入该广播包，发给客户机，欢迎它加入网络大家庭。

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs/20190529194716.png)



#### DHCP单播和广播
正常情况下，一旦有了IP地址，DHCP Server还是希望通过单播的方式发送OFFER和ACK。但是不幸的是，有的客户端协议栈的实现，如果还没有配置IP地址，就使用单播。协议栈是不接收这个包的，因为OFFER和ACK的时候，IP地址还没有配置到网卡上。所以，一切取决于客户端的协议栈的能力，如果没配置好IP，就不能接收单播的包，那就将BROADCAST设为1，以广播的形式进行交互。

#### 解决安全问题

其实DHCP协议的设计是基于内网互信的基础来设计的，而且是基于UDP协议。但是这里面的确是有风
险的。例如一个普通用户无意地或者恶意地安装一台DHCP服务器，发放一些错误或者冲突的配置；再
如，有恶意的用户发出很多的DHCP请求，让DHCP服务器给他分配大量的IP。

对于第一种情况，DHCP服务器和二层网络都是由网管管理的，可以在交换机配置只有来自某
个DHCP服务器的包才是可信的，其他全部丢弃。如果有SDN，或者在云中，非法的DHCP包根本就拦
截到虚拟机或者物理机的出口。

对于第二种情况，一方面进行监控，对DHCP报文进行限速，并且异常的端口可以关闭，一方面还是SDN或者在云中，除了被SDN管控端登记过的IP和MAC地址，其他的地址是不允许出现在虚拟机和物理机出口的，也就无法模拟大量的客户端。

#### IP地址的收回和续租

如果不用的话，收回就收回了。就像你租房子一样，如果还要续租的话，不能到了时间再续租，而是要提前一段时间给房东说。DHCP也是这样。

客户机会在租期过去50%的时候，直接向为其提供IP地址的DHCP Server发送DHCP request消息包。客户机接收到该服务器回应的DHCP ACK消息包，会根据包中所提供的新的租期以及其他已经更新的TCP/IP参数，更新自己的配置。这样，IP租用更新就完成了。

好了，一切看起来完美。DHCP协议大部分人都知道，但是其实里面隐藏着一个细节，很多人可能不会去注意。接下来，我就讲一个有意思的事情：网络管理员不仅能自动分配IP地址，还能帮你自动安装操作系统！

#### 手动配置与DHCP

在一个DHCP网络里面，如果某一台机器手动配置了一个IP地址，并且在DHCP管理的网段里的
话，DHCP服务器是会将这个地址分配给其他机器的。一旦分配了，ARP的时候，就会收到两个应
答，IP地址就冲突了。
当发生这种情况的时候，应该怎么办呢？DHCP的过程虽然没有明确如何处理，但是DHCP的客户端和
服务器都可以添加相应的机制来检测冲突。
如果由客户端来检测冲突，一般情况是，客户端在接受分配的IP之前，先发送一个ARP，看是否有应
答，有就说明冲突了，于是发送一个DHCPDECLINE，放弃这个IP地址。
如果由服务器来检测冲突，DHCP服务器会发送ping，来看某个IP是否已经被使用。如果被使用了，它
就不再将这个IP分配给其他的客户端了


#### 预启动执行环境（PXE）
其实，这个过程和操作系统启动的过程有点儿像。首先，启动BIOS。这是一个特别小的小系统，只能干特别小的一件事情。其实就是读取硬盘的MBR启动扇区，将GRUB启动起来；然后将权力交给GRUB，GRUB加载内核、加载作为根文件系统的initramfs文件；然后将权力交给内核；最后内核启动，初始化整个操作系统。

那我们安装操作系统的过程，只能插在BIOS启动之后了。因为没安装系统之前，连启动扇区都没有。因而这个过程叫做预启动执行环境（Pre-boot Execution Environment），简称PXE。

PXE协议分为客户端和服务器端，由于还没有操作系统，只能先把客户端放在BIOS里面。当计算机启动时，BIOS把PXE客户端调入内存里面，就可以连接到服务端做一些操作了。

首先，PXE客户端自己也需要有个IP地址。因为PXE的客户端启动起来，就可以发送一个DHCP的请求，让DHCP Server给它分配一个地址。PXE客户端有了自己的地址，那它怎么知道PXE服务器在哪里呢？对于其他的协议，都好办，要么人告诉他。例如，告诉浏览器要访问的IP地址，或者在配置中告诉它；例如，微服务之间的相互调用。

但是PXE客户端启动的时候，啥都没有。好在DHCP Server除了分配IP地址以外，还可以做一些其他的事情。这里有一个DHCP Server的一个样例配置：


```
ddns-update-style interim;
ignore client-updates;
allow booting;
allow bootp;
subnet 192.168.1.0 netmask 255.255.255.0
{
option routers 192.168.1.1;
option subnet-mask 255.255.255.0;
option time-offset -18000;
default-lease-time 21600;
max-lease-time 43200;
range dynamic-bootp 192.168.1.240 192.168.1.250;
filename "pxelinux.0";
next-server 192.168.1.180;
}
```

按照上面的原理，默认的DHCP Server是需要配置的，无非是我们配置IP的时候所需要的IP地址段、子网掩码、网关地址、租期等。如果想使用PXE，则需要配置next-server，指向PXE服务器的地址，另外要配置初始启动文件filename。

这样PXE客户端启动之后，发送DHCP请求之后，除了能得到一个IP地址，还可以知道PXE服务器在哪里，也可以知道如何从PXE服务器上下载某个文件，去初始化操作系统。

### 解析PXE的工作过程
首先，启动PXE客户端。第一步是通过DHCP协议告诉DHCP Server，我刚来，一穷二白，啥都没有。DHCP Server便租给它一个IP地址，同时也给它PXE服务器的地址、启动文件pxelinux.0。

其次，PXE客户端知道要去PXE服务器下载这个文件后，就可以初始化机器。于是便开始下载，下载的时候使用的是TFTP协议。所以PXE服务器上，往往还需要有一个TFTP服务器。PXE客户端向TFTP服务器请求下载这个文件，TFTP服务器说好啊，于是就将这个文件传给它。

然后，PXE客户端收到这个文件后，就开始执行这个文件。这个文件会指示PXE客户端，向TFTP服务器请求计算机的配置信息pxelinux.cfg。TFTP服务器会给PXE客户端一个配置文件，里面会说内核在哪里、initramfs在哪里。PXE客户端会请求这些文件。

最后，启动Linux内核。一旦启动了操作系统，以后就啥都好办了。
![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs/20190529194922.png)



## 网络设备的状态标识

<BROADCAST,MULTICAST,UP,LOWER_UP>是干什么的？这个叫作net_device flags，网络设备的状态标识。

UP表示网卡处于启动的状态；BROADCAST表示这个网卡有广播地址，可以发送广播包；MULTICAST表示网卡可以发送多播包；LOWER_UP表示L1是启动的，也即网线插着呢。MTU1500是指什么意思呢？是哪一层的概念呢？最大传输单元MTU为1500，这是以太网的默认值。

网络包是层层封装的。MTU是二层MAC层的概念。MAC层有MAC的头，以太网规定连MAC头带正文合起来，不允许超过1500个字节。正文里面有IP的头、TCP的头、HTTP的头。如果放不下，就需要分片来传输。

qdisc pfifo_fast是什么意思呢？qdisc全称是queueing discipline，中文叫排队规则。内核如果需要通过某个网络接口发送数据包，它都需要按照为这个接口配置的qdisc（排队规则）把数据包加入队列。

最简单的qdisc是pfifo，它不对进入的数据包做任何的处理，数据包采用先入先出的方式通过队列。pfifo_fast稍微复杂一些，它的队列包括三个波段（band）。在每个波段里面，使用先进先出规则。

三个波段（band）的优先级也不相同。band 0的优先级最高，band 2的最低。如果band 0里面有数据包，系统就不会处理band 1里面的数据包，band 1和band 2之间也是一样。

数据包是按照服务类型（Type of Service，TOS）被分配到三个波段（band）里面的。TOS是IP头里面的一个字段，代表了当前的包是高优先级的，还是低优先级的。

## ICMP 协议

它是 TCP/IP 协议族的一个子协议，用于在 IP 主机、路由器之间传递控制消息。控制消息是
指网络通不通、主机是否可达、路由是否可用等网络本身的消息。这些控制消息虽然并不传输用
户数据，但是对于用户数据的传递起着重要的作用。


## ping和tracert命令用的什么协议

ICMP

# TCP/UDP
TCP（Transmission Control Protocol 传输控制协议）是一种面向连接的、可靠的、基于字节流的传输层通信协议。

TCP通过校验和、序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现可靠性传输。

## TCP和UDP区别
![TCP、UDP协议的区别](https://user-gold-cdn.xitu.io/2018/4/19/162db5e97e9a9e01?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

UDP 在传送数据之前不需要先建立连接，远地主机在收到 UDP 报文后，不需要给出任何确认。虽然 UDP 不提供可靠交付，但在某些情况下 UDP 确是一种最有效的工作方式（一般用于即时通信），比如： QQ 语音、 QQ 视频 、直播等等

TCP 提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束后要释放连接。 TCP 不提供广播或多播服务。由于 TCP 要提供可靠的，面向连接的传输服务（TCP的可靠体现在TCP在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源），这一难以避免增加了许多开销，如确认，流量控制，计时器以及连接管理等。这不仅使协议数据单元的首部增大很多，还要占用许多处理机资源。TCP 一般用于文件传输、发送和接收邮件、远程登录等场景。


### TCP对应的协议和UDP对应的协议

1、TCP对应的协议：

（1） FTP：定义了文件传输协议，使用21端口。

（2） Telnet：一种用于远程登陆的端口，使用23端口，用户可以以自己的身份远程连接到计算机上，可提供基于DOS模式下的通信服务。

（3） SMTP：邮件传送协议，用于发送邮件。服务器开放的是25号端口。

（4） POP3：它是和SMTP对应，POP3用于接收邮件。POP3协议所用的是110端口。

（5）HTTP：是从Web服务器传输超文本到本地浏览器的传送协议。



2、UDP对应的协议：

（1） DNS：用于域名解析服务，将域名地址转换为IP地址。DNS用的是53号端口。

（2） SNMP：简单网络管理协议，使用161号端口，是用来管理网络设备的。由于网络设备很多，无连接的服务就体现出其优势。

（3） TFTP(Trival File Tran敏感词er Protocal)，简单文件传输协议，该协议在熟知端口69上使用UDP服务。


## TCP应用场景
当网络通信质量要求比较高的适合，比如要将整个数据准确无误传输给对方，用一些可靠请求：HTTP,HTTPS,FTP,POP,SMTP等



## TCP协议如何来保证传输的可靠性

TCP提供一种面向连接的、可靠的字节流服务。其中，面向连接意味着两个使用TCP的应用（通常是一个客户和一个服务器）在彼此交换数据之前必须先建立一个TCP连接。在一个TCP连接中，仅有两方进行彼此通信；而字节流服务意味着两个应用程序通过TCP链接交换8bit字节构成的字节流，TCP不在字节流中插入记录标识符。
对于可靠性，TCP通过以下方式进行保证：

- 数据包校验：目的是检测数据在传输过程中的任何变化，若校验出包有错，则丢弃报文段并且不给出响应，这时TCP发送数据端超时后会重发数据；
- 对失序数据包重排序：既然TCP报文段作为IP数据报来传输，而IP数据报的到达可能会失序，因此TCP报文段的到达也可能会失序。TCP将对失序数据进行重新排序，然后才交给应用层；
- 丢弃重复数据：对于重复数据，能够丢弃重复数据；
- 应答机制：当TCP收到发自TCP连接另一端的数据，它将发送一个确认。这个确认不是立即发送，通常将推迟几分之一秒；
- 超时重发：当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段；
- 流量控制：TCP连接的每一方都有固定大小的缓冲空间。TCP的接收端只允许另一端发送接收端缓冲区所能接纳的数据，这可以防止较快主机致使较慢主机的缓冲区溢出，这就是流量控制。TCP使用的流量控制协议是可变大小的滑动窗口协议。
## TCP为什么要建立连接
保证可靠性

## 三次握手
为了准确无误地把数据送达目标处，TCP协议采用了三次握手策略。

三次握手的目的是建立可靠的通信信道，说到通讯，++简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的++。

**步骤** ：
1. TCP服务器进程先创建传输控制块TCB，时刻准备接受客户进程的连接请求，此时服务器就进入了LISTEN（监听）状态；

2. TCP客户进程也是先创建传输控制块TCB，然后向服务器发出连接请求报文，这是报文首部中的同部位SYN=1，同时选择一个初始序列号 seq=x ，此时，TCP客户端进程进入了 SYN-SENT（同步已发送状态）状态。TCP规定，SYN报文段（SYN=1的报文段）不能携带数据，但需要消耗掉一个序号。（一次）


3. TCP服务器收到请求报文后，如果同意连接，则发出确认报文。确认报文中应该 ACK=1，SYN=1，确认号是ack=x+1，同时也要为自己初始化一个序列号 seq=y，此时，TCP服务器进程进入了SYN-RCVD（同步收到）状态。这个报文也不能携带数据，但是同样要消耗一个序号。（两次）

>接收端传回发送端所发送的 SYN 是为了告诉发送端，我接收到的信息确实就是你所发送的信号了。

>双方通信无误必须是两者互相发送信息都无误。传了 SYN，证明发送方到接收方的通道没有问题，但是接收方到发送方的通道还需要 ACK 信号来进行验证。


4. TCP客户进程收到确认后，还要向服务器给出确认。确认报文的ACK=1，ack=y+1，自己的序列号seq=x+1，此时，TCP连接建立，客户端进入ESTABLISHED（已建立连接）状态。TCP规定，ACK报文段可以携带数据，但是如果不携带数据则不消耗序号。（三次）

5. 当服务器收到客户端的确认后也进入ESTABLISHED状态，此后双方就可以开始通信了。

最开始的时候客户端和服务器都是处于CLOSED状态。主动打开连接的为客户端，被动打开连接的是服务器。
![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs/20190527142901.png)

第一次握手：Client 什么都不能确认；Server 确认了对方发送正常 ++（发送端不确定是否能发送正常，接收方不确定自身能发送正常）++

第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己接收正常，对方发送正常
++（接收方不确定自己发送正常）++

第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送接收正常
++（都正常）++

所以三次握手就能确认双发收发功能都正常，缺一不可。


>TCP报平安的包是原路返回吗？

原路返回的意思是原样返回，也就是返回也是这个过程，不一定是完全一样的路径。



### 问答
>三次握手四次挥手标志：

- URD：紧急指针标志
- PSH：push标志
- RST：重置链接标志
- seq: ==序列号，表示数据第一个字节的序号==
- ack: ==确认序列号，表示期望收到的第一个字节的序号==
- SYN：==用作建立连接时的同步信号。同步序号，用于建立连接过程==
- ACK：==用于对收到的数据进行确认。确认序号标志==
- FIN：==表示后面没有数据需要发送，连接需要关闭。==

>当面试官问你为什么需要有三次握手、三次握手的作用、讲讲三次三次握手的时候.首先很多人会先讲下握手的过程：

- 1、第一次握手：客户端给服务器发送一个 SYN 报文。
- 2、第二次握手：服务器收到 SYN 报文之后，会应答一个 SYN+ACK 报文。
- 3、第三次握手：客户端收到 SYN+ACK 报文之后，会回应一个 ACK 报文。
- 4、服务器收到 ACK 报文之后，三次握手建立完成。

==作用是为了确认双方的接收与发送能力是否正常。==

>为啥只有三次握手才能确认双方的接受与发送能力是否正常，而两次却不可以：   

- 第一次握手：客户端发送网络包，服务端收到了。这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。
- 第二次握手：服务端发包，客户端收到了。这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。**不过此时服务器并不能确认客户端的接收能力是否正常。**
- 第三次握手：客户端发包，服务端收到了。这样服务端就能得出结论：客户端的接收、发送能力正常，服务器自己的发送、接收能力也正常。

因此，需要三次握手才能确认双方的接收与发送能力是否正常。

这样回答其实也是可以的，但我觉得，这个过程的我们应该要描述的更详细一点，因为三次握手的过程中，双方是由很多状态的改变的，而这些状态，也是面试官可能会问的点。所以我觉得在回答三次握手的时候，==我们应该要描述的详细一点，而且描述的详细一点意味着可以扯久一点。加分的描述==我觉得应该是这样：

刚开始客户端处于 closed 的状态，服务端处于 listen 状态。然后

- 1、第一次握手：客户端给服务端发一个 SYN 报文，并指明客户端的初始化序列号 ISN(c)。此时客户端处于 SYN_Send 状态。
- 2、第二次握手：服务器收到客户端的 SYN 报文之后，会以自己的 SYN 报文作为应答，并且也是指定了自己的初始化序列号 ISN(s)，同时会把客户端的 ISN + 1 作为 ACK 的值，表示自己已经收到了客户端的 SYN，此时服务器处于 SYN_REVD 的状态。
- 3、第三次握手：客户端收到 SYN 报文之后，会发送一个 ACK 报文，当然，也是一样把服务器的 ISN + 1 作为 ACK 的值，表示已经收到了服务端的 SYN 报文，此时客户端处于 establised 状态。
- 4、服务器收到 ACK 报文之后，也处于 establised 状态，此时，双方以建立起了链接。

>三次握手的作用

三次握手的作用也是有好多的，多记住几个，保证不亏。例如：

- 1、确认双方的接受能力、发送能力是否正常。
- 2、指定自己的初始化序列号，为后面的可靠传送做准备。
- 3、如果是 https 协议的话，三次握手这个过程，还会进行数字证书的验证以及加密密钥的生成到。



>初始化序列（ISN）是固定的吗

- 三次握手的一个重要功能是客户端和服务端交换ISN(Initial Sequence Number), 以便让对方知道接下来接收数据的时候如何按序列号组装数据。

- ==如果ISN是固定的，攻击者很容易猜出后续的确认号，因此 ISN 是动态生成的==。

>什么是半连接队列

++服务器第一次收到客户端的 SYN 之后，就会处于 SYN_RCVD 状态，此时双方还没有完全建立其连接，服务器会把此种状态下请求连接放在一个队列里，我们把这种队列称之为半连接队列++。当然还有一个全连接队列，==就是已经完成三次握手，建立起连接的就会放在全连接队列中。如果队列满了就有可能会出现丢包现象。==

>这里在补充一点关于SYN-ACK 重传次数的问题：　

服务器发送完SYN－ACK包，如果未收到客户确认包，服务器进行首次重传，等待一段时间仍未收到客户确认包，进行第二次重传，==如果重传次数超 过系统规定的最大重传次数，系统将该连接信息从半连接队列中删除==。注意，++每次重传等待的时间不一定相同，一般会是指数增长++，例如间隔时间为 1s, 2s, 4s, 8s, ….

>三次握手过程中可以携带数据吗

也就是说，==第一次、第二次握手不可以携带数据，而第三次握手是可以携带数据的==。

为什么这样呢？大家可以想一个问题，假如第一次握手可以携带数据的话，如果有人要恶意攻击服务器，那他每次都在第一次握手中的 SYN 报文中放入大量的数据，因为攻击者根本就不理服务器的接收、发送能力是否正常，然后疯狂着重复发 SYN 报文的话，这会让服务器花费很多时间、内存空间来接收这些报文。也就是说，第一次握手可以放数据的话，++其中一个简单的原因就是会让服务器更加容易受到攻击了。++

++而对于第三次的话，此时客户端已经处于 established 状态，也就是说，对于客户端来说，他已经建立起连接了，并且也已经知道服务器的接收、发送能力是正常的了，所以能携带数据页没啥毛病。++

关于三次握手的，https 的认证过程能知道一下最好，不过我就不说了，留着写 http 面试相关时的文章再说。


## 四次挥手
四次挥手停止数据传输：任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了TCP连接。


**步骤**：
1. 客户端进程发出连接释放报文，并且停止发送数据。释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端进入FIN-WAIT-1（终止等待1）状态。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。 

>客服端停止接受数据，告诉服务器

2. 服务器收到连接释放报文，发出确认报文，ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。

>服务器接受FIN信息，发送ACK告诉客户端它知道了。
3. 客户端收到服务器的确认请求后，此时，客户端就进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。

     服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN=1，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。
>服务器发送FIN，关闭数据传输
4. 客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，必须经过2∗ *∗MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。
>客户端收到FIN信号，发送ACK了告诉服务器它知道了

- 服务器只要收到了客户端发出的确认，立即进入CLOSED状态。同样，撤销TCB后，就结束了这次的TCP连接。可以看到，服务器结束TCP连接的时间要比客户端早一些。

数据传输完毕后，双方都可释放连接。最开始的时候，客户端和服务器都是处于ESTABLISHED状态，然后客户端主动关闭，服务器被动关闭。
![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs/20190527142959.png)

### 问答



刚开始双方都处于 establised 状态，假如是客户端先发起关闭请求，则：

1、第一次挥手：客户端发送一个 FIN 报文，报文中会指定一个序列号。此时客户端处于CLOSED_WAIT1状态。

2、第二次握手：服务端收到 FIN 之后，会发送 ACK 报文，且把客户端的序列号值 + 1 作为 ACK 报文的序列号值，表明已经收到客户端的报文了，此时服务端处于 CLOSE_WAIT2状态。

3、第三次挥手：如果服务端也想断开连接了，和客户端的第一次挥手一样，发给 FIN 报文，且指定一个序列号。此时服务端处于 LAST_ACK 的状态。

4、第四次挥手：客户端收到 FIN 之后，一样发送一个 ACK 报文作为应答，且把服务端的序列号值 + 1 作为自己 ACK 报文的序列号值，此时客户端处于 TIME_WAIT 状态。需要过一阵子以确保服务端收到自己的 ACK 报文之后才会进入 CLOSED 状态

5、服务端收到 ACK 报文之后，就处于关闭连接了，处于 CLOSED 状态。

>这里特别需要主要的就是TIME_WAIT这个状态了，这个是面试的高频考点，就是要理解，为什么客户端发送 ACK 之后不直接关闭，而是要等一阵子才关闭。


这其中的原因就是，==要确保服务器是否已经收到了我们的 ACK 报文，如果没有收到的话，服务器会重新发 FIN 报文给客户端，客户端再次收到 FIN 报文之后，就知道之前的 ACK 报文丢失了，然后再次发送 ACK 报文==。

==至于 TIME_WAIT 持续的时间至少是一个报文的来回时间。一般会设置一个计时，如果过了这个计时没有再次收到 FIN 报文，则代表对方成功就是 ACK 报文，此时处于 CLOSED 状态。==


6、第3次握手失败会怎么办?

第三次失败，只有客户端处于成功状态（因为第2次服务器返回了ACK），服务器端没有接收到客户端的 ACK。
这要分几种情况讨论：

- In other words, if the ACK is dropped but the next packet is not dropped, then everything is fine. 也就是说客户端发出的 ACK 丢失了，发出的 下一个数据包 没有丢失，则服务端接收到下一个数据包（这个数据包里也会带上 ACK 信息），能够进入正常的 ESTABLISHED 状态
- 如果服务端和客户端都没有数据发送，或者服务端想发送数据（但是发不了，因为没有收到客户端的 ACK），服务器都会有定时器发送第二步SYN+ACK数据包，如果客户端再次发送ACK成功，建立连接。
- 如果一直不成功，服务器肯定会有超时设置，超时之后会给客户端发RTS报文，进入CLOSED状态，防止SYN洪泛攻击。

>这里我给出每个状态所包含的含义，有兴趣的可以看看。

- LISTEN - 侦听来自远方TCP端口的连接请求；
- SYN-SENT -在发送连接请求后等待匹配的连接请求；
- SYN-RECEIVED - 在收到和发送一个连接请求后等待对连接请求的确认；
- ESTABLISHED- 代表一个打开的连接，数据可以传送给用户；
- FIN-WAIT-1 - 等待远程TCP的连接中断请求，或先前的连接中断请求的确认；
- FIN-WAIT-2 - 从远程TCP等待连接中断请求；
- CLOSE-WAIT - 等待从本地用户发来的连接中断请求；
- CLOSING -等待远程TCP对连接中断的确认；
- LAST-ACK - 等待原来发向远程TCP的连接中断请求的确认；
- TIME-WAIT -等待足够的时间以确保远程TCP接收到连接中断请求的确认；
- CLOSED - 没有任何连接状态；




## TCP如何保证可靠传输？
1. 三次握手。
2. 将数据截断为合理的长度。应用数据被分割成 TCP 认为最适合发送的数据块（按字节编号，合理分片）
3. 超时重发。当 TCP 发出一个段后，它启动一个定时器，如果不
能及时收到一个确认就重发
4. 对于收到的请求，给出确认响应
5. 校验出包有错，丢弃报文段，不给出响应
6. 对失序数据进行重新排序，然后才交给应用层
7. 对于重复数据 ， 能够丢弃重复数据
8. 流量控制。TCP 连接的每一方都有固定大小的缓冲空间。TCP 的接收端
只允许另一端发送接收端缓冲区所能接纳的数据。这将防止较快主机致使较慢主机的缓冲
区溢出。
9. 拥塞控制。当网络拥塞时，减少数据的发送。

## 自动重传
**自动重传请求**（Automatic Repeat-reQuest，ARQ）是OSI模型中数据链路层和传输层的错误纠正协议之一。它通过使用确认和超时这两个机制，在不可靠服务的基础上实现可靠的信息传输。如果发送方在发送后一段时间之内没有收到确认帧，它通常会重新发送。ARQ包括停止等待ARQ协议和连续ARQ协议。

#### 停止等待ARQ协议
- 停止等待协议是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认（回复ACK）。如果过了一段时间（超时时间后），还是没有收到 ACK 确认，说明没有发送成功，需要重新发送，直到收到确认后再发下一个分组；
- 在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认；

**优点：** 简单

**缺点：** 信道利用率低，等待时间长


**1) 无差错情况:**

![](https://user-gold-cdn.xitu.io/2018/8/16/16541fa8c3816a90?w=514&h=473&f=png&s=9924)

发送方发送分组,接收方在规定时间内收到,并且回复确认.发送方再次发送。

**2) 出现差错情况（超时重传）:**
![](https://user-gold-cdn.xitu.io/2018/8/16/16541faefdf249ab?w=953&h=480&f=png&s=19163)
停止等待协议中超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送过的分组丢失了）。因此每发送完一个分组需要设置一个超时计时器，其重传时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为 **自动重传请求 ARQ** 。另外在停止等待协议中若收到重复分组，就丢弃该分组，但同时还要发送确认。**连续 ARQ 协议** 可提高信道利用率。发送维持一个发送窗口，凡位于发送窗口内的分组可连续发送出去，而不需要等待对方确认。接收方一般采用累积确认，对按序到达的最后一个分组发送确认，表明到这个分组位置的所有分组都已经正确收到了。

**3) 确认丢失和确认迟到**

- **确认丢失**：确认消息在传输过程丢失
  ![](https://user-gold-cdn.xitu.io/2018/8/16/16541fb6941a7165?w=918&h=461&f=png&s=19841)
   当A发送M1消息，B收到后，B向A发送了一个M1确认消息，但却在传输过程中丢失。而A并不知道，在超时计时过后，A重传M1消息，B再次收到该消息后采取以下两点措施：

    1. 丢弃这个重复的M1消息，不向上层交付。
    2. 向A发送确认消息。（不会认为已经发送过了，就不再发送。A能重传，就证明B的确认消息丢失）。
- **确认迟到** ：确认消息在传输过程中迟到
  ![](https://user-gold-cdn.xitu.io/2018/8/16/16541fdd85929e6b?w=899&h=450&f=png&s=23165)
  A发送M1消息，B收到并发送确认。在超时时间内没有收到确认消息，A重传M1消息，B仍然收到并继续发送确认消息（B收到了2份M1）。此时A收到了B第二次发送的确认消息。接着发送其他数据。过了一会，A收到了B第一次发送的对M1的确认消息（A也收到了2份确认消息）。处理如下：
    1. A收到重复的确认后，直接丢弃。
    2. B收到重复的M1后，也直接丢弃重复的M1。

#### 连续ARQ协议

连续 ARQ 协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。

**优点：** 信道利用率高，容易实现，即使确认丢失，也不必重传。

**缺点：** 不能向发送方反映出接收方已经正确收到的所有分组的信息。 比如：发送方发送了 5条 消息，中间第三条丢失（3号），这时接收方只能对前两个发送确认。发送方无法知道后三个分组的下落，而只好把后三个全部重传一次。这也叫 Go-Back-N（回退 N），表示需要退回来重传已经发送过的 N 个消息。


## 滑动窗口
TCP 利用滑动窗口实现流量控制的机制。

滑动窗口（Sliding window）是一种流量控制技术。早期的网络通信中，通信双方不会考虑网络的拥挤情况直接发送数据。由于大家不知道网络拥塞状况，同时发送数据，导致中间节点阻塞掉包，谁也发不了数据，所以就有了滑动窗口机制来解决此问题。

TCP 中采用滑动窗口来进行传输控制，滑动窗口的大小意味着接收方还有多大的缓冲区可以用于接收数据。发送方可以通过滑动窗口的大小来确定应该发送多少字节的数据。当滑动窗口为 0 时，发送方一般不能再发送数据报，但有两种情况除外，一种情况是可以发送紧急数据，例如，允许用户终止在远端机上的运行进程。另一种情况是发送方可以发送一个 1 字节的数据报来通知接收方重新声明它希望接收的下一字节及发送方的滑动窗口大小。

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/file/20190722200608.png)
## 流量控制
TCP 利用滑动窗口实现流量控制。

流量控制是为了控制发送方发送速率，保证接收方来得及接收。

接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/file/20190722202732.png)
## 拥塞控制

拥塞控制就是防止过多的数据注入网络中，这样可以使网络中的路由器或链路不致过载。拥塞控制是一个全局性的过程，和流量控制不同，流量控制指点对点通信量的控制。

#### TCP的拥塞处理



TCP的拥塞控制采用了四种算法，即 **慢开始** 、 **拥塞避免** 、**快重传** 和 **快恢复**。在网络层也可以使路由器采用适当的分组丢弃策略（如主动队列管理 AQM），以减少网络拥塞的发生。

- 慢启动：不要一开始就发送大量的数据，先探测一下网络的拥塞程度，也就是说由小到大逐渐增加拥塞窗口的大小;
 ![](https://user-gold-cdn.xitu.io/2018/8/10/1652348ada2c8fd0?w=1050&h=560&f=jpeg&s=112611)
- 拥塞避免：拥塞避免算法让拥塞窗口缓慢增长，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍，这样拥塞窗口按线性规律缓慢增长。

  

  

- 快重传：快重传要求接收方在收到一个 失序的报文段 后就立即发出 重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。
  
  

- 快恢复：快重传配合使用的还有快恢复算法，当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把ssthresh门限减半，但是接下去并不执行慢开始算法：因为如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方现在认为网络可能没有出现拥塞。所以此时不执行慢开始算法，而是将cwnd设置为ssthresh的大小，然后执行拥塞避免算法。

  
  ![快重传与快恢复](https://user-gold-cdn.xitu.io/2018/8/10/165234f0303d174b?w=1174&h=648&f=png&s=109568)


### 慢开始
发送方维持一个叫做拥塞窗口cwnd（congestion window）的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口，另外考虑到接受方的接收能力，发送窗口可能小于拥塞窗口。

慢开始算法的思路就是，不要一开始就发送大量的数据，先探测一下网络的拥塞程度，也就是说由小到大逐渐增加拥塞窗口的大小。

### 拥塞避免
拥塞避免算法让拥塞窗口缓慢增长，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样拥塞窗口按线性规律缓慢增长。
```java
当cwnd<ssthresh时，使用慢开始算法。

当cwnd>ssthresh时，改用拥塞避免算法。

当cwnd=ssthresh时，慢开始与拥塞避免算法任意。
```


为了进行拥塞控制，TCP 发送方要维持一个 **拥塞窗口(cwnd)** 的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个。

### 快速重传

快重传要求接收方在收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时捎带确认。==快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段==，而不必继续等待设置的重传计时器时间到期。
  



### 快速恢复
快恢复算法，有以下两个要点:
1. 当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把ssthresh门限减半。但是接下去并不执行慢开始算法。
2. 考虑到如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方现在认为网络可能没有出现拥塞。所以此时不执行慢开始算法，而是将cwnd设置为ssthresh的大小，然后执行拥塞避免算法。

### 丢包

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/file/20190722200658.png)


## 说一下 tcp 粘包是怎么产生的？
tcp 粘包可能发生在发送端或者接收端，分别来看两端各种产生粘包的原因：
- 发送端粘包：发送端需要等缓冲区满才发送出去，造成粘包；
- 接收方粘包：接收方不及时接收缓冲区的包，造成多个包接收。

### TCP粘包和拆包产生的原因

1. 应用程序写入数据的字节大小大于套接字发送缓冲区的大小
2. 进行MSS大小的TCP分段。MSS是最大报文段长度的缩写。MSS是TCP报文段中的数据字段的最大长度。数据字段加上TCP首部才等于整个的TCP报文段。所以MSS并不是TCP报文段的最大长度，而是：MSS=TCP报文段长度-TCP首部长度
3. 以太网的payload大于MTU进行IP分片。MTU指：一种通信协议的某一层上面所能通过的最大数据包大小。如果IP层有一个数据包要传，而且数据的长度比链路层的MTU大，那么IP层就会进行分片，把数据包分成托干片，让每一片都不超过MTU。注意，IP分片可以发生在原始发送端主机上，也可以发生在中间路由器上。

### TCP粘包和拆包的解决策略

1. 消息定长。例如100字节。
2. 在包尾部增加回车或者空格符等特殊字符进行分割，典型的如FTP协议
3. 将消息分为消息头和消息尾。
4. 其它复杂的协议，如RTMP协议等。

## socket



socket是通信的基石。支持TCP/IP等协议的基本操作单元。
应用层通过传输层进行数据通信时，TCP会遇到同时为多个应用程序进程提供并发服务的问题。多个TCP连接或多个应用程序进程可能需要通过同一个TCP协议端口传输数据。为了区别不同的应用程序进程和连接，许多计算机操作系统为应用程序与TCP／IP协议交互提供了套接字(Socket)接口。应用层可以和传输层通过Socket接口，区分来自不同应用程序进程或网络连接的通信，实现数据传输的并发服务。

![](https://raw.githubusercontent.com/binbinbin5/myPics/master/file/20190722215824.png)

### 实现socket


```
//S
public class HServerApp implements Runnable {
    public int port;

    public HServerApp(int port) {
        this.port = port;
    }

    @Override
    public void run() {
        try {
            ServerSocket server = new ServerSocket(port);
            while (true) {
                //等待client的请求
                System.out.println("waiting...");
                Socket socket = server.accept();
                // 接收客户端的数据
                DataInputStream in = new DataInputStream(socket.getInputStream());
                String string = in.readUTF();
                System.out.println("client:" + string);
                // 发送给客户端数据
                DataOutputStream out = new DataOutputStream(socket.getOutputStream());
                out.writeUTF("hi,i am hserver!i say:" + string);
                socket.close();
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    public static void main(String[] args) {
        HServerApp serverApp = new HServerApp(9050);
        serverApp.run();
    }
}

```

```
//Client
public class HClient {

    public static void main(String[] args) {
        while (true) {
            try {
                Socket socket = new Socket("10.80.1.155", 9050);
                System.out.println("please input...");
                Scanner scanner = new Scanner(System.in);
                String p = scanner.nextLine();
                if (p.equals("bye")) {
                    socket.close();
                    break;
                }
                // 发送给服务器的数据
                DataOutputStream out = new DataOutputStream(socket.getOutputStream());
                out.writeUTF(p);
                // 接收服务器的返回数据
                DataInputStream in = new DataInputStream(socket.getInputStream());
                System.out.println("hserver:" + in.readUTF());
                socket.close();
            } catch (Exception e) {
                e.printStackTrace();
            }
        }
    }
}

```


# 数据链入层协议
## ARP是什么协议，简单语言解释一下工作原理
1. 每个主机都会在自己的ARP缓冲区中建立一个ARP列表，以表示IP地址和MAC地址之间的对应关系。
1. 当源主机要发送数据时，首先检查ARP列表中是否有对应IP地址的目的主机的MAC地址，如果有，则直接发送数据，如果没有，就向本网段的所有主机发送ARP数据包，该数据包包括的内容有：源主机 IP地址，源主机MAC地址，目的主机的IP地址。
1. 当本网络的所有主机收到该ARP数据包时，首先检查数据包中的IP地址是否是自己的IP地址，如果不是，则忽略该数据包，如果是，则首先从数据包中取出源主机的IP和MAC地址写入到ARP列表中，如果已经存在，则覆盖，然后将自己的MAC地址写入ARP响应包中，告诉源主机自己是它想要找的MAC地址。
1. 源主机收到ARP响应包后。将目的主机的IP和MAC地址写入ARP列表，并利用此信息发送数据。如果源主机一直没有收到ARP响应数据包，表示ARP查询失败。

广播发送ARP请求，单播发送ARP响应。
### 如果目标IP和本机使用的IP在同一子网

如果目标IP和本机IP是同一个子网（根据本机ifconfig上的每个网卡的netmask来判断是否是同一个子网——知识点：子网掩码的作用），并且本机arp缓存没有这条IP对应的mac记录，那么给整个子网的所有机器广播发送一个 arp查询.
### 如果目标IP不是同一个子网

arp只是同一子网广播查询，如果目标IP不是同一子网的话就要经过本IP网关进行转发(知识点：网关的作用)。如果本机没有缓存网关mac（一般肯定缓存了），那么先发送一次arp查询网关的mac，只是这个icmp包发到网关上去了（mac地址填写的是网关的mac）。

## ARP攻击
地址解析协议。ARP 攻击的第一步就是 ARP 欺骗。由上述“ARP 协议的工作过程”我们知道，
ARP 协议基本没有对网络的安全性做任何思考，当时人们考虑的重点是如何保证网络通信能够正
确和快速的完成——ARP 协议工作的前提是默认了其所在的网络是一个善良的网络，每台主机在
向网络中发送应答信号时都是使用的真实身份。不过后来，人们发现 ARP 应答中的 IP 地址和 MAC
地址中的信息是可以伪造的，并不一定是自己的真实 IP 地址和 MAC 地址，由此，ARP 欺骗就产
生了。

## STP
互联网服务提供商 ISP 可以从互联网管理机构获得许多 IP 地址，同时拥有通信线路以及路由器等联网设备，个人或机构向 ISP 缴纳一定的费用就可以接入互联网。

目前的互联网是一种多层次 ISP 结构，ISP 根据覆盖面积的大小分为第一层 ISP、区域 ISP 和接入 ISP。互联网交换点 IXP 允许两个 ISP 直接相连而不用经过第三个 ISP。
![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs/f50c796c16aee351837efcac84a6b586.jpg)



## CSMA/CD 协议
++一对多通信++，一个节点发送的数据能够被广播信道上所有的节点接收到。

所有的节点都在同一个广播信道上发送数据，因此需要有专门的控制方法进行协调，避免发生冲突（冲突也叫碰撞）。++主要有两种控制方法进行协调，一个是使用信道复用技术，一是使用 CSMA/CD 协议。++


- 多点接入 ：说明这是总线型网络，许多主机以多点的方式连接到总线上。
- 载波监听 ：每个主机都必须不停地监听信道。在发送前，如果监听到信道正在使用，就必须等待。
- 碰撞检测 ：在发送中，如果监听到信道已有其它主机正在发送数据，就表示发生了碰撞。虽然每个主机在发送数据之前都已经监听到信道为空闲，但是由于电磁波的传播时延的存在，还是有可能会发生碰撞。


>记端到端的传播时延为 τ，最先发送的站点最多经过 2τ 就可以知道是否发生了碰撞，称 2τ 为 争用期 。只有经过争用期之后还没有检测到碰撞，才能肯定这次发送不会发生碰撞。当发生碰撞时，站点要停止发送，等待一段时间再发送。这个时间采用 "截断二进制指数退避算法"来确定。从离散的整数集合 {0, 1, .., (2k-1)} 中随机取出一个数，记作 r，然后取 r 倍的争用期作为重传等待时间。
![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs/20190530154422.png)


>以太网的争用期：

（1）以太网的端到端往返时延2τ称为争用期，或碰撞窗口。通常取51.2us（微秒）为争用期长度；

（2）对于10Mb/s的以太网，在争用期内可发送512bit，即64字节；

（3）以太网在发送数据时，若前64字节未发生冲突，则后续的数据就不会发生冲突了。

>最短有效帧长：

（1）如果发生冲突，则一定是在发送前的64字节之内；

（2）由于一检测到冲突就立即终止发送，这时已经发送出去的数据一定小于64字节；

（3）以太网规定了最短有效帧长为64字节，凡长度小于64字节的帧都是由于冲突而异常终止的无效帧。

>强化碰撞：

当发送数据的站一旦发现发生了数据碰撞时，除了立即停止发送数据外，还要继续发送32比特或48比特的人为干扰信号，以便让所有的用户都知道发生了碰撞。


CSMA/CD协议的要点

1. 准备发送：先检测信道；

2. 检测信道：若信道忙，则一直检测，直至信道转为空闲。若检测到信道空闲，并在96比特时间内信道保持空闲（以太网规定帧间最小间隔为9.6us，相当于96比特）就发生这个帧；

3. 在发送过程中仍不停的检测信道，即网络适配器边发送边监听。
    1. 发送成功：未发生碰撞；
    2. 发送失败：停止发送数据，并且发送人为干扰信号。

以太网每发送完一次帧，一定要把自己发送的帧暂时保留一下。如果在争用期内检测出发生了碰撞，那么还要在推迟一段时间后把这个暂时保留的帧再发送一次。

>为了更好的理解碰撞以及CSMA/CD，下面举一个例子：有一屋子的人在开讨论会，没有会议主持人控制发言。想发言的随机发言，不用举手示意。但我们还必须有个协议来协调大家的发言。这就是：如果你听见有人在发言，那么你就必须等别人讲完了才能发言（否则就干扰了别人发言）。但有时碰巧两个或更多的人同时发言了，那么一旦发生冲突，那家都必须立即停止发言，等到没有人发言了你再发言。以太网采用的CSMA/CD协议和上面场景很像。




## PPP 协议
++一对一通信++。

    因为不会发生碰撞，因此也比较简单，使用 PPP 协议进行控制。

简单，只检测差错而不去纠正差错，不使用序号，也不进行流量控制，可同时支持多种网络层协议互联网。用户通常需要连接到某个 ISP 之后才能接入到互联网，PPP 协议是用户计算机和 ISP 进行通信时所使用的数据链路层协议。PPP 的帧格式：![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs/20190530154657.png)

    - F 字段为帧的定界符
    - A 和 C 字段暂时没有意义
    - FCS 字段是使用 CRC 的检验序列
    - 信息部分的长度不超过 1500




应该满足的要求 | 不需要满足的要求
---|---
简单---这是首要的要求| 纠错
封装成帧 | 流量控制
透明性 |序号
多种类型链路 |半双工或单工链路
多种网络层协议 |多点线路	
差错检测	|
检测连接状态	|
网络层地址协商|
最大传输单元	|
数据压缩协商|	


PPP协议由3个部分组成：

1. 一个将IP数据报封装到串行链路的方法；
2. 一个用来建立、配置和测试数据链路层的数据控制协议LCP(Link  Control  Protocol)；
3. 一套网络控制协议NCP(Network  Control  Protocol)，其中的每一个协议支持不同的网络层协议。

工作状态：![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs20190530192755.png)

如上图的PPP协议的状态图可以看出，从设备之间的无链路开始，到先建立物理链路，再建立链路控制协议LCP链路。再经过鉴别后再建立网络控制协议NCP链路，然后才能交换数据。由此可见，PPP协议已经不是存粹的数据链路层的协议，它还包含了物理层和网络层的内容。











## DNS使用的协议
既使用TCP又使用UDP 

首先了解一下TCP与UDP传送字节的长度限制： 

1.  UDP报文的最大长度为512字节，而TCP则允许报文长度超过512字节。当DNS查询超过512字节时，协议的TC标志出现删除标志，这时则使用TCP发送。通常传统的UDP报文一般不会大于512字节。 

区域传送时使用TCP，主要有一下两点考虑： 

1. 辅域名服务器会定时（一般时3小时）向主域名服务器进行查询以便了解数据是否有变动。如有变动，则会执行一次区域传送，进行数据同步。区域传送将使用TCP而不是UDP，因为数据同步传送的数据量比一个请求和应答的数据量要多得多。 
2. TCP是一种可靠的连接，保证了数据的准确性。 

域名解析时使用UDP协议： 

1. 客户端向DNS服务器查询域名，一般返回的内容都不超过512字节，用UDP传输即可。不用经过TCP三次握手，这样DNS服务器负载更低，响应更快。虽然从理论上说，客户端也可以指定向DNS服务器查询的时候使用TCP，但事实上，很多DNS服务器进行配置的时候，仅支持UDP查询包。



# 从输入url到页面展示到底发生了什么？

## 1.输入地址自动补全 
当我们开始在浏览器中输入网址的时候，==浏览器其实就已经在智能的匹配可能得 url 了，他会从历史记录，书签等地方，找到已经输入的字符串可能对应的 url，然后给出智能提示，让你可以补全url地址==。

比如输入了「ba」，根据之前的历史发现 90% 的概率会访问 baidu ，==因此就会在输入回车前就马上开始建立 TCP 链接了==。对于 Chrome这种变态的浏览器，他甚至会直接从缓存中把网页渲染出来，就是说，你还没有按下「回车」键，页面就已经出来了，==再比如Chrome会在浏览器启动时预先查询10个你有可能访问的域名等等==，这里面还有很多其它策略，不详细讲了。感兴趣的推荐阅读 [High Performance Networking in Chrome](http://aosabook.org/en/posa/high-performance-networking-in-chrome.html)。





---

题外话
1. 输入框自动补全1：输入维护一个字典树，自动显示：
>比如 abcd,abc,abcf,aed 组成一个字典树，当输入ab的时候自动出现abcd,abc,abcf，但是这样维护一个字典树比较麻烦。

2. 输入框自动补全2：把全用户每天输入大量的查询关键字，我们把查询的关键字记录下来，目前通过异步队列写入数据库，用户输入的关键字可能是汉字、数字，英文，拼音，特殊字符等等，由于需要实现拼音提示，所以我们需要把汉字转换成拼音（有组件可以进行转换）。 汉字转换拼音的过程中，顺便提取出拼音缩写，要支持多音字提示，对查询串转换成拼音后，需要实现一个全排列组合，考虑到查询串可能比较长导致全排列比较的，具体算法需要做限制处理。

>比如支持前缀匹配，比如输入“ch”可能提示出“重庆”，支持缩写输入，比如输入“cq”能提示出“重庆”，多音字支持，比如输入“chongqing”或者“zhongqing”都能提示出“重庆”。


---


## 2.浏览器查找域名的 IP 地址　（URL解析/DNS解析域名）　
### URL解析
输入 URL 「回车」后，这时浏览器会对 URL 进行检查:
```
URL完整格式为：
协议://用户名:密码@子域名.域名.顶级域名:端口号/目录/文件名.文件后缀?参数=值#标志
```
- ==协议/模式==（scheme）是从该计算机获取资源的方式，一般有Http、Https、Ftp、File、Mailto、Telnet、News等协议，不同协议有不同的通讯内容格式，协议主要作用是告诉浏览器如何处理将要打开的文件；
- ==网络地址==指示该连接网络上哪一台计算机（服务器），可以是域名或者IP地址，域名或IP地址后面有时还跟一个冒号和一个端口号；
- ==端口号==如果地址不包含端口号，根据协议的类型会确定一个默认端口号。http的默认端口号为80/tcp,https端口号为443/tcp 443/udp.
- ==资源路径==指示从服务器上获取哪一项资源的等级结构路径，以斜线/分隔；
- ==文件名==一般是需要真正访问的文件，有时候，URL以斜杠“/”结尾，而隐藏了文件名，在这种情况下，URL引用路径中最后一个目录中的默认文件（通常对应于主页），这个文件常被称为 index.html 或 default.htm。
- ==动态参数==有时候路径后面会有以问号?开始的参数，这一般都是用来传送对服务器上的数据库进行动态询问时所需要的参数，有时候没有，很多为了seo优化，都已处理成伪静态了。要注意区分url和路由的区别。


浏览器对 URL 进行检查时首先判断协议，如果是 http/https 就按照 Web 来处理，另外还会对URL进行安全检查，然后直接调用浏览器内核中的对应方法，接下来是对网络地址进行处理，如果地址不是一个IP地址而是域名则通过DNS（域名系统）将该地址解析成IP地址。IP地址对应着网络上一台计算机，DNS服务器本身也有IP，你的网络设置包含DNS服务器的IP。 例如：www.zhihu.com域名请求对应获得的IP是 116.211.167.187。（==判断协议，URL安全检查，调用内核方法==）

### DNS解析域名

>DNS 在解析域名的时候有两种方式：递归查询和迭代查询，递归查询的流程如下：

1、请求一旦发起，浏览器首先要做的事情就是解析这个域名，一般来说，浏览器会首先查询浏览器缓存（DNS 在各个层级都有缓存的，相应的，缓存当然有过期时间，Time to live），如果没有找到，就会检查系统缓存，检查本地硬盘的hosts文件，这个文件保存了一些以前访问过的网站的域名和IP对应的数据。它就像是一个本地的数据库。如果找到就可以直接获取目标主机的IP地址了（注意这个地方存在安全隐患，如果有病毒把一些常用的域名，修改 hosts 文件，指向一些恶意的IP，那么浏览器也会不加判断的去连接，是的，这正是很多病毒的惯用手法）==(先查缓存后查host文件)==

2、如果本地hosts也没有找到的话，则需要再向上层找路由器缓存，路由器有自己的DNS缓存，可能就包括了查询的内容；==（路由器缓存）==

3、如果在本地的 hosts 文件没有能够找到对应的 ip 地址 ，浏览器会发出一个 DNS请求到本地DNS服务器 。本地DNS服务器一般都是你的网络接入服务器商提供，比如中国电信，中国移动。 查询你输入的网址的DNS请求到达本地DNS服务器之后，本地DNS服务器会首先查询它的缓存记录，如果缓存中有此条记录，就可以直接返回结果，此过程是递归的方式进行查询。如果没有，本地DNS服务器还要向DNS根服务器进行查询。==（本地DNS查询到根DNS查询）==

4、根DNS服务器没有记录具体的域名和IP地址的对应关系，而是告诉本地DNS服务器，你可以到域服务器上去继续查询，并给出域服务器的地址。这种过程是迭代的过程。==（域DNS查询）==

5、本地DNS服务器继续向域服务器发出请求，在这个例子中，请求的对象是.com域服务器。.com域服务器收到请求之后，也不会直接返回域名和IP地址的对应关系，而是告诉本地DNS服务器，你的域名的解析服务器的地址。==（域名解析服务器地址）==

6、最后，==本地DNS服务器向域名的解析服务器发出请求，这时就能收到一个域名和IP地址对应关系，本地DNS服务器不仅要把IP地址返回给用户电脑，还要把这个对应关系保存在缓存中==，以备下次别的用户查询时，可以直接返回结果，加快网络访问。

>虽然递归查询是默认的DNS查询方式，但是如果有以下情况发生的话，则会使用迭代的查询方式进行。
1. 情况一：DNS客户端的请求报文中没有申请使用递归查询，即在DNS请求报头部的RD字段没有置1。
2. 情况二：DNS客户端的请求报文中申请使用的是递归查询（也就是RD字段置1了），但在所配置的本地名称服务器上是禁用递归查询了（即在应答DNS报文头部的RA字段置0）。

#### DNS劫持
DNS（域名系统）的作用是把网络地址（域名，以一个字符串的形式）对应到真实的计算机能够识别的网络地址（IP地址），以便计算机能够进一步通信，传递网址和内容等。由于域名劫持往往只能在特定的被劫持的网络范围内进行，所以在此范围外的域名服务器(DNS)能够返回正常的IP地址，高级用户可以在网络设置把DNS指向这些正常的域名服务器以实现对网址的正常访问。所以域名劫持通常相伴的措施——封锁正常DNS的IP。
如果知道该域名的真实IP地址，则可以直接用此IP代替域名后进行访问。比如访问百度域名，可以把访问改为202.108.22.5，从而绕开域名劫持 。
#### 改DNS为什么导致上网变快？
其实DNS和网速关系不大。但设置正确的DNS可以加快IP的解析速度，从而提高网页的打开速度。也可以净化一些运营商广告。从而提升上网的体验。
#### DNS负载均衡
当一个网站有足够多的用户的时候，假如每次请求的资源都位于同一台机器上面，那么这台机器随时可能会蹦掉。处理办法就是用DNS负载均衡技术，它的原理是在DNS服务器中为同一个主机名配置多个IP地址,在应答DNS查询时,DNS服务器对每个查询将以DNS文件中主机记录的IP地址按顺序返回不同的解析结果,将客户端的访问引导到不同的机器上去,使得不同的客户端访问不同的服务器,从而达到负载均衡的目的｡例如可以根据每台机器的负载量，该机器离用户地理位置的距离等等。


## 3.应用层客户端发送HTTP请求
互联网内各网络设备间的通信都遵循TCP/IP协议，利用TCP/IP协议族进行网络通信时，会通过分层顺序与对方进行通信。分层由高到低分别为：应用层、传输层、网络层、数据链路层。发送端从应用层往下走，接收端从数据链路层网上走。如图所示：![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs/20190610152559.png)
从上面的步骤中得到 IP 地址后，浏览器会开始构造一个 HTTP 请求，应用层客户端向服务器端发送的HTTP请求包括：请求报头和请求主体两个部分，其中请求报头（request header）包含了至关重要的信息，包括请求的方法（GET / POST和不常用的PUT / DELETE以及更不常用的HEAD / OPTION / TRACE，一般的浏览器只能发起 GET 或者 POST 请求）、目标url、遵循的协议（HTTP / HTTPS / FTP…），返回的信息是否需要缓存，以及客户端是否发送Cookie等信息。需要注意的是，因为 HTTP 请求是纯文本格式的，所以在 TCP 的数据段中可以直接分析 HTTP 文本的。
==（准备好HTTP请求）==

## 4.建立TCP连接
当应用层的 HTTP 请求准备好后，浏览器会在传输层发起一条到达服务器的 TCP 连接，位于传输层的TCP协议为传输报文提供可靠的字节流服务。它为了方便传输，将大块的数据分割成以报文段为单位的数据包进行管理，并为它们编号，方便服务器接收时能准确地还原报文信息。TCP协议通过“三次握手”等方法保证传输的安全可靠。

“三次握手”的过程是，发送端先发送一个带有SYN（synchronize）标志的数据包给接收端，在一定的延迟时间内等待接收的回复。接收端收到数据包后，传回一个带有SYN/ACK标志的数据包以示传达确认信息。接收方收到后再发送一个带有ACK标志的数据包给接收端以示握手成功。在这个过程中，如果发送端在规定延迟时间内没有收到回复则默认接收方没有收到请求，而再次发送，直到收到回复为止。![](https://raw.githubusercontent.com/binbinbin5/myPics/master/imgs/20190610152849.png)

>假设客户端的发送了 3 个 TCP 片段（segments），编号分别是 1、2、3，如果编号为 1 的包传输时丢了，即便编号 2 和 3 已经到达也只能等待，因为 TCP 协议需要保证顺序，这个问题在 HTTP pipelining 下更严重，因为 HTTP pipelining 可以让多个 HTTP 请求通过一个 TCP 发送，比如发送两张图片，可能第二张图片的数据已经全收到了，但还得等第一张图片的数据传到。为了解决 TCP 协议的性能问题，Chrome 团队提出了 QUIC 协议，它是基于 UDP 实现的可靠传输，比起 TCP，它能减少很多来回（round trip）时间，还有前向纠错码（Forward Error Correction）等功能。目前 Google Plus、 Gmail、Google Search、blogspot、Youtube 等几乎大部分 Google 产品都在使用 QUIC，可以通过chrome://net-internals/#spdy 页面来发现。另外，浏览器对同一个域名有连接数限制，大部分是 6，但并非将这个连接数改大后就会提升性能，Chrome 团队有做过实验，发现从 6 改成 10 后性能反而下降了，造成这个现象的因素有很多，如建立连接的开销、拥塞控制等问题，而像 SPDY、HTTP 2.0 协议尽管只使用一个 TCP 连接来传输数据，但性能反而更好，而且还能实现请求优先级。



## 5. 网络层IP协议查询MAC地址
IP协议的作用是把TCP分割好的各种数据包封装到IP包里面传送给接收方。而要保证确实能传到接收方还需要接收方的MAC地址，也就是物理地址才可以。IP地址和MAC地址是一一对应的关系，一个网络设备的IP地址可以更换，但是MAC地址一般是固定不变的。ARP协议可以将IP地址解析成对应的MAC地址。当通信的双方不在同一个局域网时，需要多次中转才能到达最终的目标，在中转的过程中需要通过下一个中转站的MAC地址来搜索下一个中转目标。

## 6. 数据到达数据链路层

在找到对方的MAC地址后，已被封装好的IP包再被封装到数据链路层的数据帧结构中，将数据发送到数据链路层传输，再通过物理层的比特流送出去。这时，客户端发送请求的阶段结束。

>这些分层的意义在于分工合作，数据链路层通过 CSMA/CD 协议保证了相邻两台主机之间的数据报文传递，而网络层的 IP 数据包通过不同子网之间的路由器的路由算法和路由转发，保证了互联网上两台遥远主机之间的点对点的通讯，不过这种传输是不可靠，于是可靠性就由传输层的 TCP 协议来保证，TCP 通过慢开始，乘法减小等手段来进行流量控制和拥塞避免，同时提供了两台遥远主机上进程到进程的通信，最终保证了 HTTP 的请求头能够被远方的服务器上正在监听的 HTTP 服务器进程收到，终于，数据包在跳与跳之间被拆了又封装，在子网与子网之间被转发了又转发，最后进入了服务器的操作系统的缓冲区，服务器的操作系统由此给正在被阻塞住的 accept 函数一个返回，将他唤醒。

## 7. 服务器接收数据

接收端的服务器在链路层接收到数据包，再层层向上直到应用层。这过程中包括在传输层通过TCP协议将分段的数据包重新组成原来的HTTP请求报文。

## 8. 服务器响应请求并返回相应文件
服务接收到客户端发送的HTTP请求后，服务器上的的 http 监听进程会得到这个请求，然后一般情况下会启动一个新的子进程去处理这个请求，同时父进程继续监听。http 服务器首先会查看重写规则，然后如果请求的文件是真实存在，例如一些图片，或 html、css、js 等静态文件，则会直接把这个文件返回，如果是一个动态的请求，那么会根据 url 重写模块的规则，把这个请求重写到一个 rest 风格的 url 上，然后根据动态语言的脚本，来决定调用什么类型的动态文件脚本解释器来处理这个请求。


```
解析html以构建dom树 -> 构建render树 -> 布局render树 -> 绘制render树
```
## 9. 浏览器发送请求获取嵌入在 HTML 中的资源（如图片、音频、视频、CSS、JS等等）

其实这个步骤可以并列在步骤8中，在浏览器显示HTML时，它会注意到需要获取其他地址内容的标签。这时，浏览器会发送一个获取请求来重新获得这些文件。比如我要获取外图片，CSS，JS文件等.

这些地址都要经历一个和HTML读取类似的过程。所以浏览器会在DNS中查找这些域名，发送请求，重定向等等…

不像动态页面，静态文件会允许浏览器对其进行缓存。有的文件可能会不需要与服务器通讯，而从缓存中直接读取，或者可以放到CDN中.

==服务器的永久重定向响应==:服务器给浏览器响应一个301永久重定向响应，这样浏览器就会访问http://www.google.com/而非http://google.com/。

>为什么服务器一定要重定向而不是直接发送用户想看的网页内容呢？其中一个原因跟搜索引擎排名有关。如果一个页面有两个地址，就像http://www.yy.com/和http://yy.com/，搜索引擎会认为它们是两个网站，结果造成每个搜索链接都减少从而降低排名。而搜索引擎知道301永久重定向是什么意思，这样就会把访问带www的和不带www的地址归到同一个网站排名下。还有就是用不同的地址会造成缓存友好性变差，当一个页面有好几个名字时，它可能会在缓存里出现好几次。

### 重定向原因：
- 网站调整（如改变网页目录结构）；
- 网页被移到一个新地址；
- 网页扩展名改变(如应用需要把.php改成.Html或.shtml)。
这种情况下，如果不做重定向，则用户收藏夹或搜索引擎数据库中旧地址只能让访问客户得到一个404页面错误信息，访问流量白白丧失；再者某些注册了多个域名的网站，也需要通过重定向让访问这些域名的用户自动跳转到主站点等。

